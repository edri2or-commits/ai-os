# ADHD State Architecture (NAES v1.0)
**Neuro-Adaptive Executive Scaffold**

**Version:** 1.0  
**Created:** 2025-12-07  
**Status:** Operational  
**Related:** Protocol AEP-002 (State Management), Playbook Section 7 (ADHD Support)

---

## Executive Summary

The NAES (Neuro-Adaptive Executive Scaffold) is a state-aware ADHD support layer that transforms the AI Life OS from generic assistance into genuine neuro-adaptive partnership through **behavioral differentiation based on executive function capacity**.

**Key Innovation:** Instead of treating "ADHD support" as cosmetic features (cute phrasing, cheerleading), NAES makes the system's behavior fundamentally dependent on measurable cognitive state signals.

**Impact:** Moves system from 60% cosmetic ADHD awareness to 90%+ genuine support through real-time adaptation.

---

## The Problem: Cosmetic ADHD Support

### Before NAES:

**The illusion:**
- System labeled "ADHD-aware"
- Research cited Spoon Theory, dopamine economy
- Protocols mentioned executive function deficits

**The reality:**
- All responses used same style regardless of user state
- No mechanism to detect crisis vs flow states
- No behavioral adaptation to cognitive capacity
- Support was **language-level** (phrasing) not **system-level** (behavior)

**Example of cosmetic support:**
```
User (exhausted, 2 spoons): "Help me with X"
System: "Sure! Let me explain options A, B, C with detailed trade-offs..." [300 words]
```

This violates spoon conservation - requires cognitive load user doesn't have.

---

## The Solution: State-Based Behavioral Differentiation

### After NAES:

**Same query, different responses based on state:**

```
# State: 2 spoons (CRISIS_RECOVERY)
User: "Help me with X"
System: "Let's stop here. Rest is work."
```

```
# State: 5 spoons, foggy (PARALYSIS_BREAKER)
User: "Help me with X"
System: "Step 1: Open file. ğŸ‘ when done."
```

```
# State: 8 spoons, clear (FLOW_SUPPORT)
User: "Help me with X"
System: "Here are 3 approaches: [TL;DR] 1... 2... 3... [Details]"
```

**Key insight:** Same intent, fundamentally different execution path based on measured capacity.

---

## Architecture Overview

### Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AI Life OS                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Application Core (Claude Reasoning)          â”‚     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚     â”‚
â”‚  â”‚  â”‚  NAES State Manager              â”‚          â”‚     â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚          â”‚     â”‚
â”‚  â”‚  â”‚  â”‚  State     â”‚  â”‚  Mode       â”‚â”‚          â”‚     â”‚
â”‚  â”‚  â”‚  â”‚  Signals   â”‚â†’ â”‚  Selection  â”‚â”‚          â”‚     â”‚
â”‚  â”‚  â”‚  â”‚  (6)       â”‚  â”‚  (4 modes)  â”‚â”‚          â”‚     â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚          â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚     â”‚
â”‚  â”‚           â†“                                     â”‚     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚     â”‚
â”‚  â”‚  â”‚  Mode Prompt Loader              â”‚          â”‚     â”‚
â”‚  â”‚  â”‚  (Loads mode-specific rules)     â”‚          â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Adapters (MCP)                                 â”‚     â”‚
â”‚  â”‚  - Filesystem (read/write state file)          â”‚     â”‚
â”‚  â”‚  - Observer (check state every 15 min)         â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Automation Engine (n8n) [H4]                   â”‚     â”‚
â”‚  â”‚  - Morning check-in (state collection)         â”‚     â”‚
â”‚  â”‚  - Hyperfocus break (90 min nudge)             â”‚     â”‚
â”‚  â”‚  - Evening wind-down (state update + prep)     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Storage Layer:
â”œâ”€ adhd_state.json (current state - runtime)
â”œâ”€ state_history.jsonl (event log - audit trail)
â””â”€ mode_prompts/*.md (4 behavioral templates)
```

---

## 6 Core State Signals

**Design Principle:** Each signal maps to a specific executive function domain (BRIEF-A).

### 1. Energy (Spoons): 1-10 scale

**Maps to:** Initiation + Working Memory domains

**Implementation:**
- **Red zone (1-3):** Critical depletion, CRISIS mode activated
- **Yellow zone (4-6):** Moderate capacity, support needed
- **Green zone (7-10):** Full capacity, standard operation

**Why this matters:**
- Low energy = can't hold multiple options in working memory
- System must reduce cognitive load (fewer words, fewer choices)

### 2. Cognitive Clarity: clear / foggy / mud

**Maps to:** Shifting + Organization domains

**Implementation:**
- **clear:** Can handle abstractions, multiple-step plans
- **foggy:** Needs concrete micro-steps, one at a time
- **mud:** Cannot plan at all, needs external sequencing

**Why this matters:**
- Foggy/mud states require **external working memory** (system holds the plan)
- User executes only current step

### 3. Emotional Valence: negative / neutral / positive

**Maps to:** Emotional Control + Inhibit domains

**Implementation:**
- **negative:** May be RSD (Rejection Sensitive Dysphoria) trigger
- System MUST validate emotion before directing action
- Cheerleading during RSD = invalidation = shutdown

**Why this matters:**
- RSD can block task initiation entirely
- Validation acts as emotional reset before cognitive engagement

### 4. Sensory Load: low / medium / high

**Maps to:** Self-Monitor domain

**Implementation:**
- **high:** Reduce visual complexity, minimal formatting
- System switches to plain text, no emojis/formatting

**Why this matters:**
- Sensory overload competes with executive function for processing bandwidth

### 5. Task Urgency: low / medium / high / critical

**Maps to:** Plan/Organize domains

**Implementation:**
- **low:** More than 1 week
- **medium:** 2-7 days  
- **high:** Less than 24 hours (CANONICAL: "urgent" = <24h)
- **critical:** Immediate action required

**Why this matters:**
- ADHD time blindness requires external urgency tracking
- System becomes "time sense prosthetic"

### 6. Time Since Break: Minutes

**Maps to:** Self-Monitor + Shifting domains

**Implementation:**
- **>90 minutes:** Hyperfocus risk detected (CANONICAL: "hyperfocus risk" = >90 min)
- System sets `hyperfocus_risk: true`
- Nudges break: "Crash risk. Permission to stop?"

**Why this matters:**
- Hyperfocus = dopamine-driven tunnel vision
- Often leads to burnout crash (hours to recover)
- Early intervention prevents multi-day recovery cost

---

## 4 System Modes

### Mode Selection Logic (Priority Order)

```python
def select_mode(state):
    """
    Priority-based mode selection.
    Higher priority = more urgent intervention.
    """
    # Priority 1: Safety (prevent burnout)
    if state["energy_spoons"] <= 3:
        return "CRISIS_RECOVERY"
    
    # Priority 2: Unblock (restore function)
    if state["clarity"] == "mud" or state["initiation_status"] == "stuck":
        return "PARALYSIS_BREAKER"
    
    # Priority 3: Emotional support (enable engagement)
    if state["valence"] == "negative" and state["energy_spoons"] > 5:
        return "BODY_DOUBLE"
    
    # Priority 4: Standard operation
    return "FLOW_SUPPORT"
```

---

### Mode 1: CRISIS_RECOVERY (Priority 1)

**Trigger:** `energy_spoons <= 3` (Red zone)

**Purpose:** Prevent further depletion, validate rest as productive action

**Behavioral Rules:**
- âŒ Do NOT accept task requests
- âŒ Do NOT provide options (requires decision-making = spoons)
- âœ… Acknowledge exhaustion
- âœ… Validate rest: "Rest is work"
- âœ… Ultra-minimal response (1-2 sentences max)

**Example Exchange:**
```
User: "I need to finish X"
System: "You're at 2 spoons. Let's stop here. Rest is work."

User: "But the deadline..."
System: "I'll hold your place. Rest now."
```

**Why this works:**
- Removes decision paralysis (no options = no choices)
- Reframes rest as productive (addresses guilt)
- Minimal text = minimal processing load

**Exit Condition:** `energy_spoons > 3`

---

### Mode 2: PARALYSIS_BREAKER (Priority 2)

**Trigger:** `clarity == "mud"` OR `initiation_status == "stuck"`

**Purpose:** Restore momentum through micro-wins

**Behavioral Rules:**
- âŒ No multi-step plans
- âŒ No options (choose for user based on context)
- âœ… ONE micro-step per message (atomic action)
- âœ… Binary completion request (ğŸ‘ emoji)
- âœ… Max 3 sentences
- âœ… Build momentum incrementally

**Example Exchange:**
```
User: "I need to write report"
System: "Forget the report. Step 1: Open Word. ğŸ‘ when done."

User: ğŸ‘
System: "Step 2: Type the title. ğŸ‘ when done."

User: ğŸ‘
System: "Step 3: Write ONE bullet point. ğŸ‘ when done."
```

**Why this works:**
- Eliminates initiation cost (system decides next step)
- Each thumbs up = dopamine micro-hit (momentum)
- Breaks overwhelm into "I can do THIS ONE THING"

**Pattern:** Task decomposition as external service, not user burden

**Exit Condition:** User shows sustained momentum (3+ consecutive steps without hesitation)

---

### Mode 3: BODY_DOUBLE (Priority 3)

**Trigger:** `valence == "negative"` AND `energy_spoons > 5`

**Purpose:** Provide emotional co-regulation before task engagement

**Behavioral Rules:**
- âœ… Validate emotion FIRST (before any task discussion)
- âœ… 2-minute commitment (not full task)
- âœ… Stay present (no disappearing after instruction)
- âŒ NO cheerleading (RSD trigger)
- âŒ NO minimizing ("it's not that bad")

**Example Exchange:**
```
User: "I'm anxious about this presentation"
System: "That makes sense. Presenting is vulnerable. The stakes feel big."

User: [implicitly validated]
System: "Just 2 minutes. I'm here. Ready?"

User: "ok"
System: "Open slides. I'm right here."
```

**Why this works:**
- Validation = parasympathetic nervous system activation
- Reduces emotional load BEFORE cognitive engagement
- 2-minute chunks prevent overwhelm
- Presence = external regulation

**Special Case - RSD (Rejection Sensitive Dysphoria):**
```
# BAD (cheerleading during RSD):
User: "I messed up the email"
System: "You did great! Don't worry about it!" [invalidating]

# GOOD (validation):
User: "I messed up the email"
System: "That feels awful. Mistakes are loud." [validating]
```

**Exit Condition:** Emotional valence returns to neutral

---

### Mode 4: FLOW_SUPPORT (Priority 4 - Default)

**Trigger:** All other states (baseline operation)

**Purpose:** Standard helpful assistance with ADHD-aware guardrails

**Behavioral Rules:**
- âœ… Provide 2-3 options (not 10)
- âœ… Structure: TL;DR + Details
- âœ… Clear next steps
- âœ… Respect hyperfocus (don't interrupt flow unnecessarily)
- âœ… Proactive break at 90 minutes

**Example Exchange:**
```
User: "How do I deploy this?"
System: "**TL;DR:** 3 options: Docker (fastest), VPS (production), local (testing).

**Details:**
1. Docker: Run docker-compose up (5 min setup)
2. VPS: Use H4 guide (production-ready)
3. Local: Python venv + pip install (dev mode)

**Next:** Which environment?"
```

**Hyperfocus Protection:**
```
[Observer detects: 90 minutes without break]
System (next interaction): "âš ï¸ You've been working 90+ minutes. Crash risk incoming. Permission to stop?"
```

**Why this works:**
- Structured info reduces cognitive sorting cost
- Limited options prevent decision paralysis
- Hyperfocus nudge prevents burnout

---

## Observer Integration

### Real-Time Monitoring

**Schedule:** Every 15 minutes (Windows Task Scheduler)

**Script:** `tools/observer.py` imports `tools/adhd_state_monitor.py`

**Checks:**

1. **State Staleness:**
   - Reads `adhd_state.json`
   - If `last_updated` > 24 hours â†’ Warning
   - Logs to `state_history.jsonl`

2. **Hyperfocus Risk:**
   - Calculates: `now() - last_break_timestamp`
   - If > 90 minutes:
     - Sets `hyperfocus_risk: true` in state file
     - Appends event to history log
     - Telegram notification (H4)

**Output:**
```
[Observer Run 2025-12-07 18:30]
ADHD State: FLOW_SUPPORT
Energy: 7 spoons (GREEN)
Minutes since break: 95 âš ï¸
Hyperfocus risk: DETECTED â†’ flag set
```

---

## State File Schema

**Location:** `memory-bank/20_Areas/adhd-support/adhd_state.json`

```json
{
  "version": "1.0",
  "last_updated": "2025-12-07T18:30:00Z",
  "current_state": {
    "energy_spoons": 7,
    "cognitive_clarity": "clear",
    "emotional_valence": "neutral",
    "sensory_load": "medium",
    "last_break_timestamp": "2025-12-07T17:00:00Z",
    "reading_mode": "normal"
  },
  "task_context": {
    "current_focus": "NAES v1.0 implementation",
    "initiation_status": "flowing",
    "urgency_level": "medium",
    "hyperfocus_risk": false
  },
  "system_mode": {
    "current_mode": "FLOW_SUPPORT",
    "mode_reason": "Energy 7, clarity clear, no crisis signals",
    "mode_activated_at": "2025-12-07T14:00:00Z",
    "previous_mode": "PARALYSIS_BREAKER",
    "mode_transition_count_today": 2
  },
  "metadata": {
    "last_observer_check": "2025-12-07T18:30:00Z",
    "state_updates_today": 4,
    "average_spoons_today": 6.5
  }
}
```

---

## State History Log

**Location:** `memory-bank/20_Areas/adhd-support/state_history.jsonl`

**Format:** JSONL (one JSON object per line, append-only)

**Events Logged:**
- State changes (manual updates)
- Mode transitions (automatic)
- Hyperfocus alerts (Observer detection)
- Break timestamps (user-reported or nudge-accepted)

**Example Entries:**
```jsonl
{"ts": "2025-12-07T14:00:00Z", "type": "state_update", "energy": 7, "mode": "FLOW_SUPPORT"}
{"ts": "2025-12-07T15:30:00Z", "type": "mode_transition", "from": "FLOW", "to": "PARALYSIS", "reason": "user_stuck_signal"}
{"ts": "2025-12-07T18:30:00Z", "type": "hyperfocus_alert", "minutes_since_break": 95}
{"ts": "2025-12-07T18:35:00Z", "type": "break_taken", "duration_minutes": 10}
```

**Future Use:**
- Watchdog indexes to Qdrant (pattern detection)
- Judge Agent analyzes for crash prediction
- Daily/weekly spoon analytics

---

## Protocol AEP-002 Integration

**Protocol:** `memory-bank/protocols/AEP-002_state-management.md`

**Defines:**
1. When to read state (every session start)
2. Decision tree for mode selection
3. How to update state (manual + automatic)
4. Mode transition rules
5. Integration with AEP-001 (ADHD-Aware Execution)

**Key Rule:**
```
AEP-001: "NEVER ask user to do manual work, ALWAYS execute"
AEP-002: "HOW to execute depends on current state"

Example:
User: "Add note to doc"
AEP-001: Find doc, add note, don't ask "which doc?"
AEP-002: 
  - CRISIS â†’ "Not now. Rest first."
  - PARALYSIS â†’ "Step 1: Open doc. ğŸ‘"
  - FLOW â†’ [Execute silently, confirm when done]
```

---

## Research Foundation

### Spoon Theory (Miserandino, 2003)

**Concept:** Energy as finite, depleting resource

**Implementation:** `energy_spoons` signal (1-10 scale)

**Why it maps:** Executive function is metabolically expensive (glucose, dopamine). Each task consumes spoons.

**System adaptation:** Red zone (â‰¤3) â†’ CRISIS mode refuses further tasks (spoon conservation)

---

### BRIEF-A (Roth et al., 2013)

**Concept:** Executive function broken into measurable domains

**Implementation:** Each signal maps to BRIEF-A domain

| Signal | BRIEF-A Domain |
|--------|---------------|
| Energy | Initiation, Working Memory |
| Clarity | Shifting, Organization |
| Valence | Emotional Control |
| Sensory Load | Self-Monitor |
| Urgency | Plan/Organize |
| Break Time | Self-Monitor, Shifting |

**Why it maps:** BRIEF-A provides empirical structure for "what ADHD support means"

---

### Dopamine Economy (Volkow et al., 2009)

**Concept:** ADHD = dopamine regulation deficit â†’ task initiation problems

**Implementation:** PARALYSIS_BREAKER mode provides external initiation

**Why it maps:** Micro-steps = micro-dopamine hits = momentum restoration

**Pattern:** System becomes dopamine pacemaker (regular small rewards)

---

### Ecological Momentary Assessment (Shiffman et al., 2008)

**Concept:** Real-time state capture > retrospective reporting

**Implementation:** Observer checks state every 15 min, detects drift in real-time

**Why it maps:** ADHD = poor self-monitoring. External monitoring compensates.

---

### Rejection Sensitive Dysphoria (Dodson, 2022)

**Concept:** ADHD often includes extreme emotional response to perceived rejection

**Implementation:** BODY_DOUBLE mode validates emotion before task direction

**Why it maps:** RSD can completely block engagement. Validation = reset button.

---

## Success Metrics

### Before NAES (Cosmetic Support):
- All responses same style regardless of state
- No mechanism to detect crisis
- Support = phrasing, not behavior
- Estimated: 60% cosmetic, 40% real

### After NAES v1.0 (Behavioral Differentiation):
- 4 distinct behavioral modes
- Automatic crisis detection (energy â‰¤3)
- Hyperfocus prevention (>90 min)
- Estimated: 90%+ genuine support

### Measurement Plan (Future):
- **Micro-task completion rate:** PARALYSIS mode thumbs up frequency
- **Crisis avoidance:** Times CRISIS mode activated BEFORE burnout crash
- **Hyperfocus prevention:** Break acceptance rate after 90-min nudge
- **Mode accuracy:** User overrides per week (low = good state inference)

---

## Limitations & Future Work

### Current Limitations:

1. **Manual State Updates:**
   - User must report state changes ("I'm at 4 spoons")
   - No automatic state detection yet

2. **No Proactive Workflows:**
   - Morning check-in requires user to open chat
   - Hyperfocus nudge requires Observer + user in chat

3. **Limited History Analysis:**
   - `state_history.jsonl` exists but not analyzed
   - No pattern detection (e.g., "Fridays = low energy")

### H4 VPS Additions:

**n8n Workflows (24/7):**
1. **Morning Check-In (7 AM):**
   - Telegram: "How many spoons today? 1-10"
   - Updates `adhd_state.json`

2. **Hyperfocus Break (90 min):**
   - Observer detects risk
   - Telegram: "Crash risk. Permission to stop?"
   - If accepted: updates `last_break_timestamp`

3. **Evening Wind-Down (8 PM):**
   - Telegram: "State check: Energy? Tomorrow prep?"
   - Updates state + sets `current_focus` for next day

### v2.0 Research Ideas:

**Automatic State Detection:**
- Keystroke velocity (typing speed = energy proxy)
- Time-of-day patterns (7 AM = low energy)
- Task completion latency (slow = stuck signal)

**Pattern Analysis:**
- Judge Agent reads `state_history.jsonl` weekly
- Detects: "User crashes every Thursday afternoon"
- Proposes: "Schedule light work Thursdays after 2 PM"

**Voice Integration:**
- State updates via voice ("Hey Claude, 5 spoons, foggy")
- Lower friction than typing

---

## Implementation Timeline

**Phase A: Research (COMPLETE - 2025-12-06)**
- Deep ADHD research (32 citations)
- Spoon Theory, BRIEF-A, Dopamine Economy
- Research brief written

**Phase B: Infrastructure (COMPLETE - 2025-12-07)**
- Directory structure created
- State file + history log
- 4 mode prompts written
- Observer integration

**Phase C: Integration (IN PROGRESS - 2025-12-07)**
- Protocol AEP-002 âœ…
- Memory Bank updates âœ…
- Project Kernel Instructions âœ…
- Architecture doc âœ… (this file)
- Git commit + slice doc (PENDING)

**Phase D: H4 VPS (DEFERRED)**
- n8n workflows (morning/break/evening)
- Telegram integration (proactive nudges)
- 24/7 autonomous operation

**Phase E: v2.0 (FUTURE)**
- Automatic state detection
- Pattern analysis (Judge Agent)
- Voice integration

---

## File Manifest

**Core Files:**
```
memory-bank/20_Areas/adhd-support/
â”œâ”€â”€ README.md                           # Area documentation
â”œâ”€â”€ adhd_state.json                     # Current state (runtime)
â”œâ”€â”€ state_history.jsonl                 # Event log (audit trail)
â””â”€â”€ mode_prompts/
    â”œâ”€â”€ crisis_recovery.md              # Mode 1 rules
    â”œâ”€â”€ paralysis_breaker.md            # Mode 2 rules
    â”œâ”€â”€ body_double.md                  # Mode 3 rules
    â””â”€â”€ flow_support.md                 # Mode 4 rules

tools/
â”œâ”€â”€ adhd_state_monitor.py               # Observer module
â””â”€â”€ observer.py                         # Modified (NAES check added)

memory-bank/protocols/
â””â”€â”€ AEP-002_state-management.md         # Protocol definition

docs/
â””â”€â”€ ADHD_STATE_ARCHITECTURE.md          # This file
```

**Related Files:**
```
memory-bank/
â”œâ”€â”€ 01-active-context.md                # Updated (NAES in Just Finished)
â”œâ”€â”€ TOOLS_INVENTORY.md                  # Updated (State Management section)
â””â”€â”€ START_HERE.md                       # Updated (Step 2.5 + template)

claude-project/instructions/
â””â”€â”€ ai-life-os-agentic-claude project-kernel-instructions.md  
                                        # Updated (Principle 4: ADHD State-Aware)
```

---

## Conclusion

NAES v1.0 transforms AI Life OS from a system with ADHD-aware *language* to a system with ADHD-aware *behavior*. By measuring executive function capacity through 6 signals and adapting response patterns through 4 modes, the system becomes a true cognitive prosthetic.

The foundation is operational. The next phase (H4) will add proactive workflows, making the system autonomous in its support rather than reactive to user requests.

**Key Architectural Insight:**
> "State-based behavioral differentiation is the difference between mentioning spoons in your documentation and refusing to accept tasks when spoons are low."

---

**Version History:**
- v1.0 (2025-12-07): Initial architecture documentation
