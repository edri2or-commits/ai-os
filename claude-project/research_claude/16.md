Cognitive Infrastructure Architecture: Designing a Resilient AI Life OS for the Neurodivergent Solopreneur

1. Introduction: The Concept of the External Brain
In the contemporary digital economy, the solopreneur operates as a singular entity responsible for strategy, execution, administration, and innovation. For an individual with Attention Deficit Hyperactivity Disorder (ADHD), this multifaceted responsibility introduces a unique set of cognitive challenges. The executive function deficits associated with ADHD—specifically in working memory, task initiation, and sustained attention—create a critical reliance on external systems to maintain operational continuity. The "AI Life OS" is not merely a collection of software tools; it is a prosthetic extension of the solopreneur’s cognitive architecture, designed to offload memory, automate repetitive execution, and provide synthesis of fragmented information.

The stability of this system is paramount. For a neurotypical user, a server crash or a broken Python environment is a technical annoyance. For the ADHD solopreneur, it is a "friction event" that risks derailing an entire day's productivity through the phenomenon of task switching and hyperfocus on repair rather than value creation. Therefore, the architectural mandate for this infrastructure is threefold: Maximum Stability (the system must persist without constant supervision), Minimum Friction (interaction and maintenance must be seamless to prevent avoidance behaviors), and Disaster Recovery (restoration must be rapid and mechanical to mitigate anxiety-induced paralysis).

This report conducts an exhaustive technical and architectural analysis of two primary infrastructure patterns for hosting a "Life OS" stack consisting of Anthropic’s Claude (the reasoning engine), the Model Context Protocol (MCP) (the connectivity layer), n8n (the orchestration engine), and persistent storage. We evaluate Pattern A, a local Windows-based host utilizing the Windows Subsystem for Linux (WSL2) and Docker Desktop, against Pattern B, a remote Linux Virtual Private Server (VPS). The analysis synthesizes performance metrics, failure modes, and psychological ergonomics to recommend a definitive architecture that minimizes cognitive overhead while maximizing operational resilience.

2. Host Architecture Analysis: The Foundation of Stability
The choice of the host operating system and environment acts as the bedrock for the entire automation stack. While the application layer (n8n, Postgres) may look identical in a Docker Compose file, the underlying kernel interactions, resource scheduling, and filesystem semantics differ radically between a localized Windows environment and a remote Linux server. These differences manifest as "friction" in the user experience.

2.1 Pattern A: The Local Windows Host (WSL2 & Docker Desktop)
Windows 10 and 11 have attempted to bridge the gap between consumer usability and developer tooling through the Windows Subsystem for Linux 2 (WSL2). Unlike its predecessor (WSL1), which translated Linux system calls to Windows NT kernel calls, WSL2 runs a lightweight virtual machine utilizing a real Linux kernel alongside the host OS. This architecture promises the "best of both worlds," yet deep technical scrutiny reveals fragility vectors that are particularly detrimental to the ADHD persona.

2.1.1 The Filesystem Performance Gap (The "IO Tax")
The most significant bottleneck in a WSL2-based architecture is the performance penalty incurred when crossing the boundary between the host NTFS filesystem and the guest ext4 filesystem. Docker containers running essentially inside the WSL2 utility VM are optimized for the native ext4 filesystem. However, users frequently attempt to mount directories from the Windows host (e.g., C:\Users\Name\n8n-data) into the container to facilitate easy access via Windows Explorer.

Technical analysis confirms that cross-OS filesystem performance is severely degraded compared to native operations. File access speeds can be up to 12 times slower when a Docker container interacts with a volume mounted from the Windows NTFS partition compared to a volume residing within the WSL2 virtual hard disk (VHDX).1 This latency is not merely a matter of milliseconds; in data-intensive workflows—such as n8n processing large JSON arrays, vector embeddings for AI, or heavy logging—this "IO Tax" manifests as workflow timeouts, sluggish UI interactions, and database locks.

For the solopreneur, this creates a dilemma. To achieve acceptable performance, data must be stored inside the WSL2 filesystem. However, this isolates the data from the native Windows environment. While Microsoft provides the \\wsl$ network share to access these files, this adds a layer of abstraction that often exhibits latency or file-locking issues when accessed by Windows-based backup tools or text editors.2 If the user attempts to edit a configuration file in VS Code (Windows) while the container (Linux) is writing to it, synchronization conflicts can corrupt the file, leading to a system failure that requires deep technical troubleshooting—a high-friction event that breaks the user's flow.

2.1.2 Memory Management and Resource Contention
WSL2 operates within a lightweight Hyper-V virtual machine. To provide a seamless experience, it dynamically allocates memory from the host Windows pool. However, a well-documented issue with the vmmem process involves aggressive memory consumption without proportional release. The Linux kernel's page cache tends to grow as files are accessed, and WSL2 does not always return this memory to Windows effectively, even after the processes inside the VM have terminated.3

For a solopreneur using a single machine for video editing, creative work, and running the AI Life OS, this resource contention is critical. A "Life OS" stack running n8n, Postgres, and perhaps a vector database like Qdrant can easily consume 4-6GB of RAM. If the vmmem process balloons to 12GB+ on a 16GB or 32GB laptop, the Windows host begins to swap to disk, causing systemic lag. The ADHD user, sensitive to sensory and operational friction, effectively experiences this lag as a barrier to work. The immediate solution—shutting down Docker to free up RAM—disables the Life OS, breaking the continuity of the external brain.

2.1.3 The Fragility of Networking Modes
Windows 11 introduced "Mirrored Mode" networking for WSL2 to simplify the complex Network Address Translation (NAT) that previously made accessing WSL2 services from the LAN difficult. While Mirrored Mode promises to map the Linux localhost to the Windows localhost seamlessly, it has introduced stability regressions. Reports indicate that enabling mirrored networking can cause broadcast storms or connectivity drops when switching between Wi-Fi and Ethernet.4 Furthermore, Docker Desktop’s reliance on user-space networking proxies (like vpnkit) to bridge the Windows-Linux divide introduces overhead and potential points of failure that simply do not exist in a native Linux environment.5

2.1.4 The "Sleep Mode" Continuity Failure
Perhaps the most fatal flaw of Pattern A is the physical state of the host hardware. A laptop is designed to sleep to conserve energy. A Life OS is designed to be always-on, processing webhooks, monitoring emails, and managing schedules 24/7.

If the Windows host enters sleep mode, the execution of n8n workflows halts immediately. Scheduled triggers (e.g., "Summarize emails at 6:00 AM") will misfire or queue up, executing en masse when the machine wakes, potentially hitting API rate limits or creating a backlog that overwhelms the user. While utilities exist to prevent sleep, running a high-performance laptop 24/7 accelerates hardware degradation and increases electricity costs, adding "maintenance friction".6

2.2 Pattern B: The Remote VPS Host (Linux)
Pattern B shifts the infrastructure from a local application to a remote server (Virtual Private Server). This decouples the "brain" from the "body" (the laptop), treating the automation stack as critical infrastructure rather than desktop software.

2.2.1 Native Performance and Stability
A VPS running a standard Linux distribution (e.g., Ubuntu 24.04 LTS) offers a native ext4 filesystem and a kernel optimized for server workloads. There is no virtualization overhead for filesystem calls, no vmmem ballooning issues impacting the desktop GUI, and no complex networking bridges to traverse. The stability profile is fundamentally higher because the environment is single-purpose: it exists solely to run the stack.

Evidence suggests that even low-cost VPS instances (e.g., 2 vCPU, 4GB RAM) outperform significantly more powerful local machines running Docker Desktop due to the absence of the virtualization tax and Windows background processes.1

2.2.2 The "Always-On" Advantage
The primary value proposition for the ADHD solopreneur is the decoupling of automation from local presence. A remote VPS ensures that webhooks from payment processors (Stripe), scheduling tools (Calendly), or email providers are received and processed regardless of whether the user’s laptop is open, closed, or undergoing a Windows Update restart. This reliability builds trust. The user learns that the system works for them, not because of them.

2.2.3 Operational Friction: Setup vs. Maintenance
Critics of the VPS approach cite the "setup friction" (SSH keys, firewall configuration, hardening) as a barrier. However, this is a one-time "hyperfocus" task. Once configured, a Linux server with unattended upgrades enabled requires near-zero interaction. In contrast, the "maintenance friction" of a local Windows setup—dealing with Docker Desktop updates, Windows sleep settings, and resource contention—is chronic and interruptive. For the neurodivergent user, chronic friction is far more damaging to productivity than acute setup complexity.6

2.3 Host Recommendation: The Remote Imperative
Based on the requirement for maximum stability and minimum friction, the Remote VPS is the superior architectural choice. The Windows/WSL2 pattern introduces too many variables (sleep, resource contention, cross-OS IO) that undermine the reliability required for a Life OS.

Strategic Recommendation: The solopreneur should treat the n8n/storage stack as "infrastructure" hosted remotely, while treating Claude Desktop as a "client" hosted locally. This hybrid approach leverages the strengths of both environments.

3. Orchestration Layer Architecture: n8n & Persistence
n8n serves as the central nervous system of the Life OS, routing data between the LLM (Claude) and the solopreneur’s digital tools. Its internal configuration determines whether the system handles load gracefully or fails silently.

3.1 Database Architecture: The SQLite vs. PostgreSQL Decision
n8n defaults to using SQLite, a serverless, file-based database. For a single user, this appears attractive due to zero configuration requirements. However, architectural analysis reveals that SQLite is a "fragility trap" for an AI Life OS.

3.1.1 The Concurrency and Locking Bottleneck
SQLite manages concurrency through file locking. When a write operation occurs, the entire database file is often locked. In a simple automation scenario, this is acceptable. However, an AI Life OS is dynamic:
- Webhooks: External services hit the system asynchronously.
- UI Interaction: The user browses execution history or edits workflows.
- Background Tasks: Scheduled agents poll for data.

If a long-running AI workflow (which writes execution data to the DB) overlaps with a webhook ingestion or a user saving a workflow, SQLite can encounter SQLITE_BUSY errors. The operation fails. For an ADHD user, a silent failure of a "Reminder" workflow or a "Client Lead" workflow creates anxiety and necessitates checking logs—high friction.8

Furthermore, migration from SQLite to PostgreSQL after the fact is a non-trivial operation involving exporting data, converting schema types, and handling encryption keys. This is a classic "technical debt" trap that solopreneurs often fall into, leading to data loss or downtime later.10

3.1.2 PostgreSQL: The Stability Standard
PostgreSQL utilizes Multi-Version Concurrency Control (MVCC) and row-level locking. This allows the n8n execution engine to write logs, the webhook listener to ingest data, and the user to query history simultaneously without blocking.

While PostgreSQL requires a separate container, the operational overhead is minimal in a Docker Compose stack. The memory footprint (approx. 70-100MB for a personal workload) is a worthy trade-off for the elimination of database-level locks.

Recommendation: The architecture must utilize PostgreSQL from Day 1. The cost of setup is minutes; the cost of SQLite failure is trust.12

3.2 Execution Data Management: The Self-Cleaning System
A common failure mode for self-hosted n8n instances is disk saturation. n8n stores the inputs and outputs of every node execution as JSON. Over weeks, this can accumulate to gigabytes of data, eventually filling the VPS disk and causing the Docker daemon to crash.

An ADHD-friendly system must be self-maintenance.

Pruning Configuration: The architecture must enforce aggressive data pruning via environment variables.
- EXECUTIONS_DATA_PRUNE=true: Enables the pruning worker.
- EXECUTIONS_DATA_MAX_AGE=168: Retains data for 7 days. This provides a sufficient window for debugging errors without allowing infinite growth.
- DB_POSTGRESDB_VACUUM_ON_STARTUP=true: Ensures the database reclaims space automatically.12

3.3 Scalability: Monolith vs. Queue Mode
n8n offers a "Queue Mode" where the webhook listener, main process, and worker processes are decoupled using Redis. This allows for horizontal scaling.

However, for a single solopreneur, Queue Mode introduces significant complexity:
- Requires an additional Redis container.
- Requires managing multiple worker containers.
- Debug logs are split across containers.

Research indicates that a single monolithic n8n instance, given sufficient RAM (e.g., 4GB), can handle thousands of daily executions—far beyond the needs of a single user. The complexity of Queue Mode violates the "Minimum Friction" requirement.14

Recommendation: Stick to the Monolithic architecture. Vertical scaling (upgrading the VPS RAM) is preferred over horizontal scaling (adding complexity) for this persona.

4. The Intelligence Layer: Claude Desktop & MCP
The integration of Anthropic's Claude Desktop (the reasoning interface) with the remote n8n stack (the tool executor) via the Model Context Protocol (MCP) represents the most sophisticated and novel part of this architecture. It is also the area with the highest potential for configuration friction due to protocol mismatches.

4.1 The Connectivity Paradox: Local vs. Remote
Claude Desktop is a local application running on Windows. It connects to MCP servers to extend its capabilities (e.g., "Read my calendar," "Trigger an n8n workflow").

Claude's Preference: Claude Desktop natively supports MCP servers running locally via stdio (standard input/output). It spawns a process (like node server.js) and communicates via stdin/stdout pipes.15

The Architecture's Reality: Our n8n instance is running remotely on a VPS for stability.

The Conflict: Claude Desktop cannot intuitively "spawn" a remote process via stdio. While Anthropic has introduced support for remote HTTP/SSE connections in Enterprise/Team plans, the support for individual users often requires specific workarounds or "developer" configurations.16

4.2 Bridging Strategies: Solving the Transport Layer
To connect the local Windows client to the remote Linux brain, we must bridge the transport gap.

4.2.1 Strategy A: The SSH Stdio Bridge
This method leverages the existing secure SSH connection to the VPS. We configure Claude Desktop to execute a local command that pipes input/output across an SSH tunnel to the remote server.

Configuration Pattern:
```json
{
  "mcpServers": {
    "n8n-remote": {
      "command": "ssh",
      "args": [
        "-i", "C:\\Users\\User\\.ssh\\id_ed25519",
        "user@100.x.y.z",
        "docker", "exec", "-i", "n8n", "n8n-mcp-server"
      ]
    }
  }
}
```

Mechanism: Claude runs ssh. SSH connects to the VPS. On the VPS, it runs docker exec to talk to the n8n container's MCP agent.

Pros: Highly secure (uses SSH keys). No new ports need to be opened on the VPS.
Cons: High latency per "turn" of conversation due to SSH handshake overhead if not optimized (ControlMaster). Requires ssh.exe to be correctly configured in Windows PATH.15

4.2.2 Strategy B: The SSE Proxy (Recommended)
n8n’s native MCP implementation utilizes Server-Sent Events (SSE) for server-to-client communication. Since Claude Desktop on Windows primarily expects stdio, we use a lightweight local proxy called mcp-remote (or similar adapters) to translate.

Configuration Pattern:
On Windows: Install Node.js.
Config:
```json
{
  "mcpServers": {
    "n8n": {
      "command": "npx",
      "args": [
        "-y",
        "mcp-remote",
        "http://100.x.y.z:5678/mcp/sse"
      ],
      "env": {
         "MCP_auth_token": "..."
      }
    }
  }
}
```

Mechanism: npx downloads and runs the proxy locally. The proxy connects via HTTP to the remote n8n instance (over the VPN/Mesh network) and converts the SSE stream into stdio for Claude.

Pros: Native protocol handling. Lower latency than initiating a fresh SSH shell for every command.
Cons: Requires Node.js on the Windows host.18

Recommendation: Strategy B is superior for the "Life OS" feel due to responsiveness. It requires the n8n instance to be reachable via a private IP, which leads us to the Network Architecture.

5. Network & Security Architecture: The Zero-Trust Mesh
Exposing the "Brain" (n8n/Postgres) to the public internet creates a massive attack surface. Hardening a public server requires fail2ban, complex firewalls, and constant vigilance—high friction. The solution is to remove the server from the public internet entirely using a Mesh VPN.

5.1 The Mesh Solution: Tailscale
Tailscale (built on WireGuard) creates a private, encrypted overlay network.

Deployment: Install Tailscale on the VPS and the Windows Laptop.
Result: The VPS gets a private IP (e.g., 100.64.0.5) accessible only from the user's devices.

Application:
- n8n binds to 0.0.0.0 inside the container, but the Docker port mapping on the host binds only to the Tailscale interface or 127.0.0.1.
- Accessing the n8n UI: The user types http://100.64.0.5:5678 in their browser. No public DNS, no Nginx reverse proxy, no Let's Encrypt certificate renewal headaches.20
- MCP Connection: The mcp-remote proxy connects to the Tailscale IP.

5.2 The Public Interface: Cloudflare Tunnel
While the management and MCP layers should be private, webhooks (e.g., from Stripe, GitHub, Mailgun) are public by definition. They cannot reach a private Tailscale IP.

Solution: Cloudflare Tunnel.

Mechanism: A cloudflared container runs in the Docker stack. It establishes an outbound connection to Cloudflare's edge network. Config: You define a public hostname (e.g., hooks.solopreneur.com) that routes traffic specifically to the n8n webhook endpoint. Security: This exposes only the webhook processing port, not the entire server. Cloudflare provides DDoS protection and Web Application Firewall (WAF) capabilities out of the box.

5.3 Comparative Analysis: Tailscale vs. Cloudflare vs. Public IP
Feature | Public IP + Nginx | Tailscale Only | Cloudflare Tunnel | Hybrid (Recommended)
---|---|---|---|---
Exposure | Full Server (Port 443) | None (Private) | Specific HTTP Routes | Private Mgmt + Public Hooks
Security | Reliance on UFW/Fail2Ban | Authenticated Mesh | Edge Protection | Defense in Depth
Maintenance | High (SSL renewal, config) | Zero (Auto-auth) | Low (Docker container) | Low
Webhook Support | Yes | No (Internal only) | Yes | Yes
Friction | High | Low | Medium | Balanced

Conclusion: The Hybrid Model (Tailscale for UI/MCP + Cloudflare Tunnel for Webhooks) offers the "Maximum Stability" of a locked-down server with the necessary connectivity for external tools.22

6. Disaster Recovery: Engineering for the "Bus Factor of One"
For the ADHD solopreneur, "disaster recovery" (DR) is often a source of dread. Complexity in backup systems leads to abandonment. If a restore process takes 20 steps, the system is effectively broken. The requirement is a fully automated, immutable backup with a "one-command" restore capability.

6.1 The 3-2-1 Rule for Containerized Stacks
The industry standard 3-2-1 rule (3 copies, 2 media types, 1 offsite) must be adapted for Docker.

6.1.1 The Docker Volume Challenge
You cannot simply copy the /var/lib/docker/volumes folder while the database is running. This results in corrupted, inconsistent backups due to in-flight transactions.23

6.2 The Solution: Restic + Automated Snapshots
Restic is a modern backup program that supports encryption, deduplication, and various backends (S3, B2, local).

6.2.1 The Backup Container
We implement a dedicated backup service in the Docker Compose stack.
- Image: mazzolino/restic (or similar wrapper).
- Volume Mounting: It mounts the n8n and Postgres data volumes as read-only.
- Dump Strategy: For Postgres, we use pg_dump to create a consistent SQL file before the snapshot. For n8n files, we snapshot the directory.
- Schedule: The container runs a cron job (e.g., 3:00 AM).24

6.2.2 Destination: Backblaze B2
Backblaze B2 is selected for its low cost ($0.005/GB/mo) and S3 compatibility. Restic encrypts the data client-side (on the VPS) before uploading, ensuring privacy.

6.3 The "Panic Button" Restore Protocol
Disaster recovery is not about backing up; it is about restoring. The solopreneur needs a pre-written restore.sh script stored in a separate location (e.g., Notion, password manager).

The Protocol:
1) Provision: Spin up new VPS.
2) Install: Docker & Tailscale.
3) Execute: Run restore.sh.
- The script pulls the Restic repo.
- It restores the latest snapshot to the /data directory.
- It starts the Docker containers.

Time to Recovery (RTO): < 15 minutes.

This mechanical process removes the cognitive load of "fixing" the server. You don't fix; you replace and restore.

7. Psychological Ergonomics: System Trust and ADHD
While technical, this architecture is fundamentally designed to address neurodivergent needs.
- Trust: By moving to a VPS, the user knows the system runs even if they forget to charge their laptop. This reduces the "checking" compulsion.
- Friction Reduction: By pinning versions and automating backups, the "maintenance" tasks are automated. The user does not need to remember to back up.
- Focus Preservation: By handling the "IO Tax" and memory issues of WSL2, the local computer remains snappy for creative work, preventing frustration-induced distraction.

8. Detailed Implementation Blueprint
This section translates the architectural decisions into a concrete deployment specification.

8.1 Infrastructure Specifications
Provider: Hetzner Cloud (CPX11 or CPX21) or DigitalOcean (Droplet).
OS: Ubuntu 24.04 LTS (Minimal).
Specs: 2 vCPU, 4GB RAM (Minimum for smooth Java/Node operations within containers). 40GB NVMe.

8.2 Docker Compose Configuration (The "Stack")
This docker-compose.yml file embodies the recommendations: Postgres DB, Monolithic n8n, Cloudflare Tunnel, and Restic Backup.

```yaml
version: '3.8'

services:
  # --------------------------------------------------------------------------------
  # Service 1: n8n - The Orchestration Engine
  # --------------------------------------------------------------------------------
  n8n:
    image: n8nio/n8n:1.76.0  # Pinned version for stability [25]
    restart: unless-stopped
    command: "start"
    environment:
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=postgres
      - DB_POSTGRESDB_PORT=5432
      - DB_POSTGRESDB_DATABASE=n8n
      - DB_POSTGRESDB_USER=n8n
      - DB_POSTGRESDB_PASSWORD=${POSTGRES_PASSWORD}
      - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY}
      - N8N_HOST=${TAILSCALE_IP}          # Private Mesh IP
      - WEBHOOK_URL=https://hooks.domain.com # Public Tunnel URL
      - EXECUTIONS_DATA_PRUNE=true        # Self-cleaning 
      - EXECUTIONS_DATA_MAX_AGE=168       # 7 Days retention
      - N8N_METRICS=true                  # Observability
    ports:
      - "127.0.0.1:5678:5678"             # Bind ONLY to localhost (accessed via Tailscale)
    volumes:
      - n8n_data:/home/node/.n8n
    depends_on:
      postgres:
        condition: service_healthy

  # --------------------------------------------------------------------------------
  # Service 2: PostgreSQL - The Data Persistence Layer
  # --------------------------------------------------------------------------------
  postgres:
    image: postgres:16-alpine
    restart: unless-stopped
    environment:
      - POSTGRES_USER=n8n
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=n8n
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test:
      interval: 5s
      timeout: 5s
      retries: 5

  # --------------------------------------------------------------------------------
  # Service 3: Cloudflare Tunnel - Public Ingress for Webhooks
  # --------------------------------------------------------------------------------
  cloudflared:
    image: cloudflare/cloudflared:latest
    restart: unless-stopped
    command: tunnel run
    environment:
      - TUNNEL_TOKEN=${TUNNEL_TOKEN}

  # --------------------------------------------------------------------------------
  # Service 4: Restic - Automated Disaster Recovery
  # --------------------------------------------------------------------------------
  backup:
    image: mazzolino/restic
    restart: unless-stopped
    hostname: n8n-backup
    environment:
      - RUN_ON_STARTUP=true
      - CRON_SCHEDULE=0 3 * * *           # Run at 3 AM UTC
      - RESTIC_REPOSITORY=s3:s3.us-west-000.backblazeb2.com/n8n-backup
      - RESTIC_PASSWORD=${RESTIC_PASSWORD}
      - AWS_ACCESS_KEY_ID=${B2_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${B2_KEY_SECRET}
      - BACKUP_CRON_COMMAND="pg_dump -h postgres -U n8n n8n > /dump/db.sql && restic backup /data /dump"
    volumes:
      - n8n_data:/data/n8n:ro             # Read-only mount of n8n data
      - postgres_data:/data/postgres:ro   # Read-only mount of DB data
    depends_on:
      - postgres

volumes:
  n8n_data:
  postgres_data:
```

8.3 The Client-Side Config (Windows)
To bridge the local Claude Desktop to this remote stack via the Tailscale mesh:

File: %APPDATA%\Claude\claude_desktop_config.json

```json
{
  "mcpServers": {
    "n8n-remote": {
      "command": "npx",
      "args": [
        "-y",
        "mcp-remote",
        "http://100.x.y.z:5678/mcp/sse"
      ],
      "env": {
        "MCP_AUTH_TOKEN": "your-n8n-token-here"
      }
    }
  }
}
```

Note: Replace 100.x.y.z with the Tailscale IP of the VPS.

9. Conclusion
The architectural analysis decisively favors the Remote VPS (Pattern B) over the Local Windows/WSL2 (Pattern A) for an ADHD solopreneur’s AI Life OS.

The decision matrix is driven by the "Solopreneur's Hierarchy of Needs":
- Reliability (Base): The VPS offers a 24/7 uptime guarantee and native filesystem performance that WSL2 cannot match due to OS sleep cycles and the virtualization IO tax.
- Continuity: PostgreSQL ensures that database locks do not silently kill workflows, preserving trust in the system.
- Security: The Tailscale Mesh architecture eliminates the need for public port exposure, reducing anxiety about hacks.
- Recoverability: Automated Restic snapshots convert disaster recovery from a crisis into a checklist.
- Connectivity: The Hybrid MCP Bridge allows the local Claude interface to wield the remote server's power, providing a seamless "bionic" experience.

This architecture incurs a small monthly operating cost ($5-10) but pays massive dividends in cognitive clarity. It transforms the AI stack from a fragile hobbyist project into resilient enterprise-grade infrastructure, tailored specifically for the neurodivergent mind that requires its tools to be as reliable as gravity.

Summary Table: Final Architectural Stack
Layer | Component | Justification
---|---|---
Host | Linux VPS (Ubuntu) | 24/7 Uptime, Native I/O, No "Sleep Mode" issues.
Orchestration | n8n (Monolith) | Simple to maintain, sufficient for single user.
Database | PostgreSQL | Prevents SQLITE_BUSY locks, enables concurrency.
Internal Network | Tailscale | Secure, zero-config access to UI and MCP.
External Network | Cloudflare Tunnel | Secure ingress for public webhooks only.
Client Bridge | mcp-remote via Node.js | Low-latency bridge for Claude Desktop (Windows).
Backup | Restic to S3 | Encrypted, deduplicated, "set and forget."1
