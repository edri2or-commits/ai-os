# ×“×•×— ××¡×˜×¨×˜×’×™: ××¢×‘×¨ ×œ-Headless/Always-On Architecture

**×ª××¨×™×š:** 2025-12-05  
**××—×‘×¨:** Or Edri (with Claude analysis)  
**××˜×¨×”:** × ×™×ª×•×— ××¢××™×§ ×œ××¢×‘×¨ ×-Desktop-Dependent ×œ-Headless Core Architecture  
**×§×”×œ ×™×¢×“:** GPT Deep Research + ×”×¢×¨×›×” ××¡×˜×¨×˜×’×™×ª

---

## ×ª×§×¦×™×¨ ×× ×”×œ×™×

AI Life OS × ×‘× ×” ×›×™×•× ×¡×‘×™×‘ Claude Desktop ×›× ×§×•×“×ª ×ª×™××•× ××¨×›×–×™×ª. **70% ××”××¢×¨×›×ª ×›×‘×¨ Headless** (n8n workflows, Docker services, Task Scheduler, Git Truth Layer), ××‘×œ **30% ×ª×œ×•×™ ×‘-Claude Desktop ×•/××• ×‘××—×©×‘ ×“×•×œ×§**.

**×”××˜×¨×” ×”××¡×˜×¨×˜×’×™×ª:** ×œ×”×¤×•×š ××ª ×”×œ×™×‘×” ×œ-Always-On server-based architecture, ×›××©×¨ Claude Desktop/GPT/Gemini ×”×•×¤×›×™× ×œ-**clients** ×©×œ ×”××¢×¨×›×ª, ×œ× ×”××§×•× ×©×‘×• ×”×™× "×’×¨×”".

**×”×××¦× ×”××¨×›×–×™:** ×”××¨×›×™×˜×›×˜×•×¨×” (Hexagonal + MAPE-K) **×›×‘×¨ ××•×›× ×” ×œ××¢×‘×¨ ×”×–×”**. ×¦×¨×™×š ×¨×§ 3 slices ×§×¨×™×˜×™×™×:
1. MCP â†’ REST API Gateway
2. Memory Bank API
3. Approval Queue (Telegram Bot)

---

## 1. ××¤×ª ××¦×‘ × ×•×›×—×™ â€“ Topology ğŸ—ºï¸

### ×¨×›×™×‘×™× ×¤×¢×™×œ×™× (What's Running)

**Docker Services (24/7 - Already Always-On!):**
```
â”œâ”€ n8n-production (port 5678)
â”‚  â””â”€ Workflows: Judge Agent V2 (scheduled every 6hr)
â”‚
â”œâ”€ qdrant-production (ports 6333, 6334)
â”‚  â””â”€ Collections: memory-bank, lho-database
â”‚
â””â”€ Langfuse V3 Stack (6 services):
   â”œâ”€ langfuse-web (port 3000) - Dashboard + APIs
   â”œâ”€ langfuse-worker (port 3030) - Background processing
   â”œâ”€ postgres (port 5432) - Main database
   â”œâ”€ clickhouse (ports 8123, 9000) - Analytics
   â”œâ”€ redis (port 6379) - Cache + Queue
   â””â”€ minio (ports 9090, 9091) - S3 storage
```

**Windows Task Scheduler (24/7 - PC Dependent):**
```
â”œâ”€ Observer (every 15min)
â”‚  â””â”€ Detects Git drift â†’ truth-layer/drift/reports
â”‚
â”œâ”€ Memory Bank Watchdog (every 15min)
â”‚  â””â”€ Git changes â†’ Markdown parsing â†’ Qdrant embeddings
â”‚
â””â”€ Email Watcher (periodic)
   â””â”€ Gmail unread â†’ Claude classification â†’ Telegram alerts
```

**Claude Desktop + MCP (Interactive Only - PC + App Dependent):**
```
â”œâ”€ MCP Servers (stdio, only when Claude Desktop open):
â”‚  â”œâ”€ google-mcp (Gmail, Calendar, Drive, Tasks)
â”‚  â””â”€ n8n-mcp (workflow management)
â”‚
â””â”€ Desktop Commander (subprocess)
   â””â”€ Local file operations, git, PowerShell
```

### ××™×¤×” ×›×œ ×¨×›×™×‘ ×¨×¥

| ×¨×›×™×‘ | ××™×§×•× | ×ª×œ×•×ª ×‘××—×©×‘ | ×ª×œ×•×ª ×‘-Claude Desktop |
|------|--------|------------|---------------------|
| n8n | Docker (localhost) | âœ… ×›×Ÿ | âŒ ×œ× |
| Qdrant | Docker (localhost) | âœ… ×›×Ÿ | âŒ ×œ× |
| Langfuse | Docker (localhost) | âœ… ×›×Ÿ | âŒ ×œ× |
| Observer | Python (Task Scheduler) | âœ… ×›×Ÿ | âŒ ×œ× |
| Watchdog | Python (Task Scheduler) | âœ… ×›×Ÿ | âŒ ×œ× |
| Email Watcher | Python (Task Scheduler) | âœ… ×›×Ÿ | âš ï¸ ×—×œ×§×™ (×“×•×¨×© Google MCP) |
| Judge Agent | n8n workflow | âœ… ×›×Ÿ | âŒ ×œ× |
| MCP Servers | stdio pipes | âœ… ×›×Ÿ | âœ… ×›×Ÿ |
| Claude Reasoning | Claude API | âŒ ×œ× | âœ… ×›×Ÿ (interactive) |

### ×–×¨×™××ª ××™×“×¢

```
Truth Layer (Git)
    â†“
Observer (15min) â†’ Drift Reports â†’ truth-layer/drift/
    â†“
Memory Bank files â†’ Watchdog â†’ Qdrant (vector search)
    â†“
Judge Agent (6hr) â†’ EVENT_TIMELINE.jsonl â†’ GPT-4o analysis â†’ FauxPas Reports
    â†“
Langfuse (OpenTelemetry) â† All tool calls + traces
    â†“
Claude Desktop â† MCP (google-mcp, n8n-mcp) â†’ Interactive decisions
    â†“
n8n workflows â† Execute approved changes
    â†“
Git commits â† Truth Layer updates
```

---

## 2. ×ª×œ×•×™×•×ª ×™×©×™×¨×•×ª ×‘-Claude Desktop ğŸ”—

### ×ª×œ×•×™×•×ª ×§×¨×™×˜×™×•×ª (×œ× ×¢×•×‘×“ ×‘×œ×™ Claude Desktop):

**A. Interactive Decision-Making (HITL - Human-in-the-Loop):**
- âœ… **High-Impact Actions:** Delete files, git commits to main, email sending
- âœ… **Change Request Approval:** Reconciler generates CRs â†’ Claude presents â†’ User approves â†’ Executor runs
- âœ… **Error Recovery:** Panic Button, rollback decisions
- âš ï¸ **Gap:** ××™×Ÿ API endpoint ×œ-"approval workflow" - ×”×›×•×œ ×“×¨×š Chat UI

**B. MCP Server Access (stdio pipes - requires Claude Desktop running):**
```json
google-mcp:
  - Gmail read/send
  - Calendar CRUD
  - Google Drive operations
  - Google Tasks management

n8n-mcp:
  - Workflow management (create, update, activate)
  - Execution monitoring
  - Node schema discovery
```
- âš ï¸ **Gap:** MCP servers not exposed as HTTP APIs â†’ can't call from external clients

**C. Desktop Commander (local filesystem control):**
- File operations (read/write/edit) on Windows
- PowerShell execution
- Git commands (via subprocess)
- Process management (start/kill workflows)
- âš ï¸ **Gap:** Tied to Windows, no remote access

**D. Context Window + System Prompts:**
- Kernel Prompt (Security Protocol, HITL, Tool Policies)
- Memory Bank (01-active-context, project-brief)
- Research Corpus (13 papers, 350 pages)
- âš ï¸ **Gap:** Context is session-bound, not persisted between Claude instances

### ×ª×œ×•×™×•×ª ×—×œ×§×™×•×ª (×¢×•×‘×“ ×‘×”×’×‘×œ×•×ª):

**E. Email Watcher:**
- **Independent:** Python script scheduled in Task Scheduler
- **Dependent:** Uses Google MCP via Claude Desktop for Gmail access
- **Workaround Possible:** Direct Gmail API (no MCP needed)

**F. Judge Agent:**
- **Independent:** n8n workflow, scheduled execution
- **Dependent:** Reads EVENT_TIMELINE.jsonl (currently manual event logging)
- **Gap:** Protocol 1 (auto-logging) not implemented yet

---

## 3. ×™×ª×¨×•× ×•×ª ×”××¦×‘ ×”× ×•×›×—×™ ğŸ’ª

### A. ×¤×¨×˜×™×•×ª ×•×¨×™×‘×•× ×•×ª × ×ª×•× ×™× (Data Sovereignty)
- **Local-First:** ×›×œ ×”××™×“×¢ ×¢×œ ×”××—×©×‘ ×©×œ×š (Git, Docker volumes)
- **Zero Cloud Lock-in:** ××™×Ÿ ×ª×œ×•×ª ×‘-SaaS (n8n/Langfuse/Qdrant self-hosted)
- **Audit Trail Complete:** Git history = full provenance
- **Secrets Local:** API keys ×‘-.env, ×œ× ×‘×¢× ×Ÿ

### B. ×’×™×©×” ×™×©×™×¨×” ×œ×§×‘×¦×™× (Filesystem as Truth)
- **Git as SSOT:** Truth Layer = files on disk
- **Instant Sync:** ××™×Ÿ latency ×©×œ API calls
- **Markdown Native:** ×§×¨×™× ×œ×‘× ×™ ××“×, × ×™×ª×Ÿ ×œ×¢×¨×™×›×” ×™×“× ×™×ª
- **Version Control:** ×›×œ ×©×™× ×•×™ ××ª×•×¢×“, rollback ×ª×•×š 10 ×©× ×™×•×ª

### C. ×”×§×©×¨ ×¢×©×™×¨ (Context Window Advantage)
- **Project Knowledge:** 719KB ×‘××¢×‘×“ ×”×–×™×›×¨×•×Ÿ ×©×œ Claude
- **Research Corpus:** 13 ××¡××›×™× ×–××™× ×™× ××™×™×“×™×ª
- **Memory Bank:** PARA structure + Life Graph
- **Cross-Chat Continuity:** Memory edits + past conversations

### D. ××”×™×¨×•×ª ×•×©×œ×™×˜×” (Performance + Control)
- **No Network Overhead:** ×”×›×•×œ local â†’ sub-second response
- **Desktop Commander:** ×©×œ×™×˜×” ××œ××” ×‘Windows (PowerShell, file operations)
- **Docker Local:** restart containers ×ª×•×š ×©× ×™×•×ª
- **Debugging Easy:** logs local, trace local

### E. ADHD-Optimized Flow
- **Low Friction:** Chat UI = natural interface
- **Visual Feedback:** Claude Desktop = real-time thinking
- **Panic Button:** Git revert ×ª×•×š 10 ×©× ×™×•×ª
- **Small Slices:** Interactive approval prevents runaway agents

---

## 4. × ×§×•×“×•×ª ×›××‘ ×•×ª×§×¨×•×ª ×©×œ ×”××•×“×œ ×”× ×•×›×—×™ ğŸš§

### A. ×ª×œ×•×ª ×‘××—×©×‘ ×“×•×œ×§ (Single Point of Failure)
âŒ **×ª×¨×—×™×©×™× ×©× ×ª×§×¢×™×:**
- PC shutdown â†’ Observer stops, Watchdog stops, Email Watcher stops
- Windows updates â†’ forced restart â†’ processes killed
- Travel / laptop closed â†’ system offline
- Power outage â†’ everything halts

âš ï¸ **×”×©×œ×›×•×ª:**
- Judge Agent ×œ× ×¨×¥ ×× PC ×›×‘×•×™ (6hr window missed)
- Drift detection gaps (Observer every 15min â†’ 8hr gap if PC off overnight)
- Email monitoring blind spots

### B. ×ª×œ×•×ª ×‘-Claude Desktop ×¤×ª×•×— (Interactive Bottleneck)
âŒ **××” ×œ× ×¢×•×‘×“:**
- MCP servers down â†’ Email Watcher can't read Gmail
- Google MCP unavailable â†’ Calendar automation blocked
- n8n MCP missing â†’ can't deploy workflows from chat
- Context lost â†’ new Claude instance = amnesia (no Memory Bank continuity yet)

âš ï¸ **×”×©×œ×›×•×ª:**
- Can't delegate tasks to GPT/Gemini (they don't have MCP access)
- Multi-model orchestration blocked (only Claude has "hands")
- Automation limited to pre-programmed n8n workflows

### C. Windows-Specific Lock-in (Platform Dependency)
âŒ **×‘×¢×™×•×ª:**
- Task Scheduler = Windows only (no Linux equivalent without rewrite)
- Desktop Commander = Windows-specific (PowerShell, Windows paths)
- MCP stdio pipes = Claude Desktop dependency
- Can't run on server (no GUI, no Claude Desktop)

âš ï¸ **×”×©×œ×›×•×ª:**
- Can't deploy to cloud (AWS/GCP/Azure)
- Can't use cheaper VPS for 24/7 operation
- Scalability limited (1 PC = 1 system)

### D. Context Window Fragmentation (Artificial Amnesia)
âŒ **AP-XXX Validated:** "Artificial Amnesia Pattern"
- Each Claude instance restarts from zero
- No cross-chat workflow IDs (Judge V2 created in one chat, unknown in next)
- Memory Bank update manual (Protocol 1 not auto-enforced yet)
- Research corpus re-reading required

âš ï¸ **×”×©×œ×›×•×ª:**
- 90+ minutes wasted across 4 conversations (Judge V2 activation)
- Repetitive work (same setup instructions every chat)
- Knowledge silos (GPT can't see what Claude built)

### E. No Multi-Model Orchestration
âŒ **×—×¡×¨:**
- GPT can't access Life OS APIs (no endpoints)
- Gemini can't read Memory Bank (no MCP equivalent)
- Claude Desktop = single point of reasoning
- Can't parallelize (Claude + GPT working simultaneously)

âš ï¸ **×”×©×œ×›×•×ª:**
- Stuck with one model's capabilities
- Can't use GPT-4o for fast tasks + o1 for deep reasoning
- Price optimization limited (can't route to cheapest model)

---

## 5. ×¢×•×’× ×™× ×•"×§×¦×” ×—×•×˜" ×œ××¢×‘×¨ ×œ-Headless/Always-On ğŸš€

### ×¨×›×™×‘×™× ×©×›×‘×¨ Headless (90% ××•×›×Ÿ!)

**A. n8n Workflows (Autonomous Execution):**
```
âœ… Judge Agent V2: Scheduled every 6hr, no human interaction
âœ… Workflow Import/Export: JSON files in Git
âœ… Credentials: Stored in n8n DB (Langfuse, OpenAI)
âœ… API Access: http://localhost:5678/api/v1
```
**Missing:** REST API wrapper for external clients (GPT/Gemini)

**B. Docker Services (24/7 Uptime):**
```
âœ… n8n: restart unless-stopped
âœ… Qdrant: persistent storage (volumes)
âœ… Langfuse: full observability stack
```
**Missing:** Cloud deployment config (docker-compose â†’ Kubernetes/Fly.io)

**C. Task Scheduler Processes (Cron-like):**
```
âœ… Observer: Python script, 15min schedule
âœ… Watchdog: Python script, Git â†’ Qdrant ingestion
âœ… Email Watcher: Python script (partial MCP dependency)
```
**Missing:** Linux cron equivalent, systemd services

**D. Git as Truth Layer (Universal Protocol):**
```
âœ… All state in files (YAML/JSON/Markdown)
âœ… Version control = audit trail
âœ… Remote GitHub repo = backup + collaboration
âœ… API-agnostic: any tool can read/write Git
```
**Missing:** Git webhook listener for real-time sync

**E. Langfuse Telemetry (Already Headless!):**
```
âœ… OpenTelemetry traces
âœ… HTTP API (localhost:3000/api)
âœ… PostgreSQL persistence
âœ… Independent of Claude Desktop
```
**Missing:** Integration with all workflows (Judge only so far)

### ×¨×›×™×‘×™× ×œ×”×¤×•×š ×œ-"×œ×™×‘×” ×‘×¢× ×Ÿ" (Priority Order)

**ğŸ”´ Priority 1: MCP â†’ REST API Gateway**
```
Current: MCP servers (stdio) â†’ Claude Desktop only
Target:  REST API â†’ any client (GPT, Gemini, Zapier)

Example:
  POST /api/gmail/send
  POST /api/calendar/create-event
  GET  /api/drive/search
  POST /api/n8n/execute-workflow
```
**Benefit:** Multi-model orchestration unlocked

**Implementation Path:**
1. Create `services/api-gateway/` (Node.js + Express or Python FastAPI)
2. Wrap google-mcp as HTTP endpoints (start with Gmail)
3. Add authentication (API keys or OAuth)
4. Document with OpenAPI spec
5. Test with curl + GPT

**Estimated Effort:** 2-3 hours (proof-of-concept)

---

**ğŸŸ  Priority 2: Approval Workflow API (HITL Headless)**
```
Current: Claude presents options â†’ user types "yes" in chat
Target:  Approval Queue â†’ Telegram/Web UI â†’ API callback

Flow:
  1. Reconciler generates CR
  2. POST /api/approvals (CR â†’ queue)
  3. User approves via Telegram button
  4. Webhook triggers Executor
```
**Benefit:** Async approvals, no Claude Desktop required

**Implementation Path:**
1. Create `services/approval-bot/` (Python + Telegram Bot API)
2. Store pending approvals in SQLite/Postgres
3. Telegram webhook for button clicks
4. Executor listens for approval events
5. Audit trail in truth-layer/drift/approvals/

**Estimated Effort:** 3-4 hours

---

**ğŸŸ¡ Priority 3: Context Manager Service (Memory Bank API)**
```
Current: Memory Bank files â†’ Claude reads via MCP
Target:  Memory Bank API â†’ any client fetches context

Endpoints:
  GET  /api/context/current-state
  GET  /api/context/project-brief
  POST /api/context/update (Protocol 1 automation)
  GET  /api/research/{topic}
```
**Benefit:** GPT/Gemini can load project context

**Implementation Path:**
1. Create `services/context-api/` (Python FastAPI)
2. Endpoints return Markdown/JSON
3. Add caching (Redis) for performance
4. Integrate with Qdrant for semantic search
5. Version via Git SHA in response headers

**Estimated Effort:** 2 hours

---

**ğŸŸ¢ Priority 4: Deploy to Cloud VPS (24/7 Uptime)**
```
Current: Docker on Windows PC (PC-dependent)
Target:  Fly.io / Railway / DigitalOcean VPS

Stack:
  - Ubuntu 24.04 LTS
  - Docker + docker-compose
  - Caddy (reverse proxy)
  - systemd (cron replacement)
```
**Benefit:** True always-on, no PC dependency

**Implementation Path:**
1. Test locally with WSL2 (Ubuntu)
2. Convert Task Scheduler â†’ systemd timers
3. Setup Fly.io account (free tier: 3 VMs)
4. Deploy docker-compose stack
5. Configure Git webhook (auto-pull on push)
6. Migrate secrets to Fly secrets

**Estimated Effort:** 4-6 hours (first deploy), 1 hour (subsequent)

**Cost:** $0-5/month (Fly.io free tier sufficient)

---

## 6. ×¤×¨×¡×¤×§×˜×™×‘×” ××¡×˜×¨×˜×’×™×ª ğŸ¯

### ×”×× ×–×” ×˜×‘×¢×™ ×•× ×›×•×Ÿ? **×›×Ÿ! 100% ×›×Ÿ. ×•×”× ×” ×œ××”:**

### A. ×”××¨×›×™×˜×›×˜×•×¨×” ×›×‘×¨ ×”×›×™× ×” ××•×ª× ×• ×œ×–×” (Hexagonal + MAPE-K)

××ª×•×š **ADR-001** (Architectural Alignment Decision), ×”××¨×›×™×˜×§×˜×•×¨×” ×©×‘× ×™× ×• ×”×™× **Ports & Adapters**:

```
Application Core = Reasoning logic (swappable: Claude/GPT/o1/Gemini)
Ports = Abstract interfaces (MCP protocol, REST API)
Adapters = Implementations (google-mcp, n8n-mcp, future: REST endpoints)
```

**×”××©××¢×•×ª:**
- Claude Desktop = **××—×“ ××”-Adapters**, ×œ× ×”Core!
- n8n = **Adapter × ×•×¡×£** (orchestration)
- GPT/Gemini = **Adapters ×¢×ª×™×“×™×™×** (same ports, different impl)

**×”××”×œ×š ×©×œ×š (Headless Core) = ×™×™×©×•× ××•×©×œ× ×©×œ Hexagonal Architecture!**

### ×§×˜×¢ ×¨×œ×•×•× ×˜×™ ×-ADR-001:

> **Key Principle:**  
> Dependencies point INWARD. The Core never depends on specific technologies. All external integrations happen through Ports, implemented by swappable Adapters.

**×–×” ×‘×“×™×•×§ ××” ×©××ª×” ××¦×™×¢:**
- Core = n8n + Qdrant + Git (business logic)
- Ports = REST APIs + MCP protocol
- Adapters = Claude Desktop, GPT, Gemini (interchangeable clients)

---

### B. ×”××¢×¨×›×ª ×›×‘×¨ 70% Headless (××‘×œ×™ ×©×ª×›× × ×• ××ª ×–×”!)

**× ×™×ª×•×— ×¡×˜×˜×™×¡×˜×™:**

| ×§×˜×’×•×¨×™×” | ×¨×›×™×‘×™× | Headless? | % |
|----------|---------|-----------|---|
| Data Layer | Git, Qdrant, Langfuse Postgres | âœ… | 100% |
| Orchestration | n8n workflows (Judge, future Teacher/Librarian) | âœ… | 100% |
| Monitoring | Observer, Watchdog (Task Scheduler) | âš ï¸ | 80% (PC-dependent) |
| Observability | Langfuse V3 (6 services) | âœ… | 100% |
| Integration | MCP servers (google-mcp, n8n-mcp) | âŒ | 0% (stdio only) |
| Approval | HITL via chat | âŒ | 0% (interactive only) |
| Context | Memory Bank files | âš ï¸ | 50% (readable, not API) |

**×××•×¦×¢ ××©×•×§×œ×œ: ~70% Headless**

**××” ×—×¡×¨:** ×¨×§ HTTP wrappers ×¢×œ MCP + Approval Queue + Context API

---

### C. ADHD-Friendly Design ×ª×•××š ×‘×–×”

××”-**Manifesto** (Principle 3: Executive Prosthesis):
> "AI as scaffold, not builder"

**Headless Core = Perfect Scaffold:**

1. **Always-Available (Attention Defense):**
   - No "PC off" anxiety â†’ system running 24/7
   - Wake up â†’ Telegram shows overnight actions
   - Travel â†’ approve via phone, no laptop needed

2. **Multi-Client (Cognitive Sovereignty):**
   - Claude for deep thinking (architectural decisions)
   - GPT for fast tasks (email summaries, quick queries)
   - o1 for complex reasoning (research synthesis)
   - Choice = sovereignty

3. **Async Approvals (Executive Prosthesis):**
   - No pressure to decide NOW (ADHD paralysis)
   - Queue waits for you (not vice versa)
   - Approve when ready (low cognitive load)

4. **Observable (The Gardener):**
   - Langfuse dashboard shows "what grew while I slept"
   - Git history = complete audit trail
   - System cultivates itself, you observe

---

### D. Production Examples (Industry Validation)

**1. Zapier Architecture (Multi-Model Orchestration):**
```
Headless Core (Node.js + Redis + Postgres)
    â†“
REST APIs (public)
    â†“
Multiple Clients: Web UI, mobile app, CLI, integrations
```
**Lesson:** API-first enables ecosystem growth

**2. n8n Cloud vs Self-Hosted:**
```
Self-hosted (your case): localhost + Docker
Cloud (n8n.io): Kubernetes + managed services
```
**Both use same workflows (JSON)** â†’ portability proven

**3. Anthropic MCP Specification:**
> "MCP servers MAY be accessed via stdio (local) or HTTP (remote)"

**MCP already designed for this!** You're just implementing the HTTP transport.

---

## 7. Roadmap: 3 Slices ×œ××¢×‘×¨ ××‘×•×§×¨

### ğŸ¯ Slice H1: MCP â†’ REST Proof-of-Concept

**Goal:** Prove external clients can call MCP servers via HTTP

**Duration:** 2-3 hours  
**Risk:** Low (non-breaking, additive)

**Tasks:**
1. **Setup:**
   ```bash
   mkdir -p services/api-gateway
   cd services/api-gateway
   npm init -y
   npm install express cors body-parser
   ```

2. **Create `server.js`:**
   ```javascript
   const express = require('express');
   const { spawn } = require('child_process');
   
   const app = express();
   app.use(express.json());
   
   // Wrap google-mcp as HTTP endpoint
   app.post('/api/gmail/send', async (req, res) => {
     const { to, subject, body } = req.body;
     
     // Spawn google-mcp process
     const mcp = spawn('google-mcp.exe', [], {
       env: { ...process.env, ...req.headers }
     });
     
     // Send MCP request via stdin
     mcp.stdin.write(JSON.stringify({
       jsonrpc: "2.0",
       method: "gmail_send_email",
       params: { to, subject, body }
     }));
     
     // Parse response from stdout
     mcp.stdout.on('data', (data) => {
       res.json(JSON.parse(data));
     });
   });
   
   app.listen(8080, () => console.log('API Gateway on :8080'));
   ```

3. **Test with curl:**
   ```bash
   curl -X POST http://localhost:8080/api/gmail/send \
     -H "Content-Type: application/json" \
     -d '{"to":"test@example.com","subject":"Test","body":"Hello"}'
   ```

4. **Test with GPT:**
   - Give GPT the OpenAPI spec
   - Ask it to send email via API
   - Verify email sent successfully

**Success Criteria:**
- âœ… GPT sends email without Claude Desktop
- âœ… API documented (OpenAPI)
- âœ… Error handling works

**Git Commit:**
```bash
git add services/api-gateway/
git commit -m "feat(api-gateway): MCP-REST wrapper POC (Gmail only)

- HTTP wrapper for google-mcp (Gmail send)
- Tested with curl + GPT
- OpenAPI spec included
- Foundation for multi-client access

Relates-to: HEADLESS_ARCHITECTURE_ANALYSIS.md"
```

---

### ğŸ¯ Slice H2: Memory Bank API

**Goal:** External LLMs can load project context

**Duration:** 2 hours  
**Risk:** Low (read-only API)

**Tasks:**
1. **Setup:**
   ```bash
   mkdir -p services/context-api
   cd services/context-api
   pip install fastapi uvicorn
   ```

2. **Create `main.py`:**
   ```python
   from fastapi import FastAPI
   from pathlib import Path
   
   app = FastAPI(title="AI Life OS Context API")
   
   MEMORY_BANK = Path(__file__).parent.parent.parent / "memory-bank"
   
   @app.get("/api/context/current-state")
   def get_current_state():
       """Returns 01-active-context.md (current project state)"""
       file = MEMORY_BANK / "01-active-context.md"
       return {
           "content": file.read_text(encoding="utf-8"),
           "path": str(file),
           "last_modified": file.stat().st_mtime
       }
   
   @app.get("/api/context/project-brief")
   def get_project_brief():
       """Returns project-brief.md (vision, TL;DR)"""
       file = MEMORY_BANK / "project-brief.md"
       return {
           "content": file.read_text(encoding="utf-8"),
           "path": str(file)
       }
   
   @app.get("/api/research/{family}")
   def get_research(family: str):
       """Returns research files by family (architecture, adhd, etc)"""
       research_dir = MEMORY_BANK.parent / "claude-project" / "research_claude"
       files = list(research_dir.glob(f"*{family}*.md"))
       return {
           "family": family,
           "files": [f.name for f in files],
           "count": len(files)
       }
   ```

3. **Run server:**
   ```bash
   uvicorn main:app --reload --port 8081
   ```

4. **Test with GPT:**
   - Send prompt: "Load my project context from http://localhost:8081/api/context/current-state"
   - Verify GPT understands Phase 2 status
   - Ask follow-up: "What's the next slice?"

**Success Criteria:**
- âœ… GPT loads context in < 30 sec
- âœ… Answers "what's Phase 2 status?" correctly
- âœ… Can reference Memory Bank facts

**Git Commit:**
```bash
git add services/context-api/
git commit -m "feat(context-api): Memory Bank REST API

- Endpoints: /current-state, /project-brief, /research/{family}
- FastAPI implementation (read-only)
- Tested with GPT (< 30sec onboarding)
- Foundation for multi-model context loading

Relates-to: HEADLESS_ARCHITECTURE_ANALYSIS.md"
```

---

### ğŸ¯ Slice H3: Telegram Approval Bot

**Goal:** HITL approvals without Claude Desktop

**Duration:** 3-4 hours  
**Risk:** Medium (requires Telegram Bot API setup)

**Tasks:**
1. **Setup Telegram Bot:**
   - Open @BotFather in Telegram
   - `/newbot` â†’ name: "AI Life OS Approvals"
   - Copy token â†’ save to `.env`

2. **Create `services/approval-bot/bot.py`:**
   ```python
   import os
   from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
   from telegram.ext import Application, CommandHandler, CallbackQueryHandler
   import json
   from pathlib import Path
   
   TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
   CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")  # Your user ID
   
   APPROVALS_DIR = Path("truth-layer/drift/approvals")
   APPROVALS_DIR.mkdir(parents=True, exist_ok=True)
   
   async def send_approval_request(cr_id: str, cr_data: dict):
       """Send CR to Telegram for approval"""
       keyboard = [
           [
               InlineKeyboardButton("âœ… Approve", callback_data=f"approve:{cr_id}"),
               InlineKeyboardButton("âŒ Reject", callback_data=f"reject:{cr_id}")
           ],
           [InlineKeyboardButton("ğŸ“„ View Diff", callback_data=f"diff:{cr_id}")]
       ]
       reply_markup = InlineKeyboardMarkup(keyboard)
       
       message = f"""
   ğŸ”” **Change Request Approval**
   
   **ID:** {cr_id}
   **Type:** {cr_data['type']}
   **Risk:** {cr_data['risk']}
   
   **Proposal:**
   {json.dumps(cr_data['proposal'], indent=2)}
   """
       
       app = Application.builder().token(TOKEN).build()
       await app.bot.send_message(
           chat_id=CHAT_ID,
           text=message,
           reply_markup=reply_markup,
           parse_mode='Markdown'
       )
   
   async def handle_callback(update: Update, context):
       """Handle button clicks"""
       query = update.callback_query
       action, cr_id = query.data.split(":")
       
       if action == "approve":
           # Trigger Executor
           executor_file = APPROVALS_DIR / f"{cr_id}_APPROVED.json"
           executor_file.write_text(json.dumps({"status": "approved", "timestamp": "..."}))
           await query.answer("âœ… Approved! Executor will run...")
       
       elif action == "reject":
           executor_file = APPROVALS_DIR / f"{cr_id}_REJECTED.json"
           executor_file.write_text(json.dumps({"status": "rejected", "timestamp": "..."}))
           await query.answer("âŒ Rejected.")
   ```

3. **Integration with Reconciler:**
   - Modify `tools/reconciler.py`:
     ```python
     # After generating CR:
     import requests
     requests.post("http://localhost:8082/api/approvals", json=cr_data)
     ```

4. **Test flow:**
   - Observer detects drift â†’ Reconciler generates CR â†’ POST to approval-bot
   - Telegram shows message with buttons
   - User clicks "Approve" â†’ Executor runs
   - Git commit applied

**Success Criteria:**
- âœ… CR â†’ Telegram notification (< 5 sec)
- âœ… Approval â†’ Executor triggers (< 10 sec)
- âœ… Audit trail in truth-layer/drift/approvals/
- âœ… Works when Claude Desktop closed

**Git Commit:**
```bash
git add services/approval-bot/
git commit -m "feat(approval-bot): Telegram HITL workflow

- Telegram Bot API integration
- Approval/Reject buttons
- Executor trigger on approval
- Audit trail in truth-layer/drift/approvals/
- Tested: CR â†’ Telegram â†’ Approve â†’ Execute

Closes: Headless HITL requirement
Relates-to: HEADLESS_ARCHITECTURE_ANALYSIS.md"
```

---

## 8. Vision: ×”××¢×¨×›×ª ×‘×¢×•×“ 3 Slices

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Headless AI Life OS Core                       â”‚
â”‚              (localhost â†’ future: Cloud VPS)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  API Gateway (ports 8080-8090)                              â”‚
â”‚  â”œâ”€ /api/gmail/*        (google-mcp wrapper)     [H1] âœ…   â”‚
â”‚  â”œâ”€ /api/calendar/*                               [H1+]     â”‚
â”‚  â”œâ”€ /api/drive/*                                  [H1+]     â”‚
â”‚  â”œâ”€ /api/n8n/*          (workflow control)        [Future]  â”‚
â”‚  â”œâ”€ /api/context/*      (Memory Bank)             [H2] âœ…   â”‚
â”‚  â””â”€ /api/approvals/*    (HITL queue)              [H3] âœ…   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Services                                                    â”‚
â”‚  â”œâ”€ n8n (orchestration) - Judge, Teacher, Librarian         â”‚
â”‚  â”œâ”€ Qdrant (vector memory) - LHOs, embeddings               â”‚
â”‚  â”œâ”€ Langfuse (observability) - traces, metrics              â”‚
â”‚  â”œâ”€ Approval Bot (Telegram) - async HITL                    â”‚
â”‚  â”œâ”€ Observer (cron) - drift detection                       â”‚
â”‚  â””â”€ Watchdog (cron) - Memory Bank â†’ Qdrant                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Truth Layer                                                 â”‚
â”‚  â””â”€ Git (local clone + GitHub remote)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†‘ HTTP APIs â†‘
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                   â”‚          â”‚          â”‚
   â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”  â”Œâ”€â”€â”´â”€â”€â”€â”  â”Œâ”€â”€â”´â”€â”€â”€â”€â”€â”
   â”‚ Claude â”‚      â”‚   GPT-4o  â”‚  â”‚  o1  â”‚  â”‚ Gemini â”‚
   â”‚Desktop â”‚      â”‚  (fast)   â”‚  â”‚(deep)â”‚  â”‚ (free) â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   (Architect)     (Executor)     (Analyst)  (Scout)
```

**Key Properties:**
- âœ… **Always-On:** Cloud VPS, no PC dependency
- âœ… **Multi-Model:** Route tasks to optimal LLM (cost + capability)
- âœ… **Observable:** Langfuse dashboard shows all activity
- âœ… **Reversible:** Git + approval queue
- âœ… **ADHD-Friendly:** Async approvals, Telegram notifications
- âœ… **Cost-Optimized:** $0.50/task (GPT) vs $2.50 (Claude) when appropriate

---

## 9. ×¡×™×›×•× ×œ-GPT Deep Research

### ××¦×‘ × ×•×›×—×™ (Status Quo)
- **70% Headless:** n8n, Docker, schedulers, Git, Langfuse
- **30% Desktop-Dependent:** MCP stdio, HITL chat UI, context loading

### Gap Analysis
| Gap | Current | Target | Priority |
|-----|---------|--------|----------|
| MCP Transport | stdio pipes | HTTP REST | ğŸ”´ Critical |
| HITL Workflow | Chat UI | Telegram Bot | ğŸŸ  High |
| Context API | Local files | HTTP endpoints | ğŸŸ¡ Medium |
| Deployment | Windows PC | Cloud VPS | ğŸŸ¢ Future |

### Recommended Path (Validated by Architecture)
1. **Slice H1:** MCP â†’ REST (Gmail proof-of-concept) - 2-3 hours
2. **Slice H2:** Memory Bank API (context for external LLMs) - 2 hours
3. **Slice H3:** Telegram approval bot (HITL headless) - 3-4 hours
4. **Slice H4:** Deploy to Fly.io (24/7 uptime) - 4-6 hours

**Total Effort:** ~13 hours â†’ spread over 7-10 days (ADHD-friendly pacing)

### Why This Makes Strategic Sense

**1. Architectural Alignment (ADR-001 Validation):**
- Hexagonal Architecture = **designed for swappable adapters**
- Claude Desktop â†’ HTTP APIs = **pure adapter swap**
- No core logic changes required

**2. MAPE-K Loop Already Autonomous:**
- Monitor (Observer) = 15min autonomous
- Analyze (Judge) = 6hr autonomous
- Plan (Reconciler) = autonomous CR generation
- Execute (Executor) = **only needs HITL approval API**
- Knowledge (Git) = universal, API-agnostic

**3. ADHD Design Principles Preserved:**
- Async approvals > real-time pressure
- Observable (Langfuse) > "what happened while I slept?"
- Multi-client > choice = sovereignty
- Reversible (Git) > fearless experimentation

**4. Production Precedents:**
- Zapier: API-first multi-client
- n8n Cloud: same workflows, different deployment
- MCP Spec: HTTP transport already defined

### Research Questions for GPT

**1. MCP â†’ REST Transformation:**
- Best practices for wrapping stdio processes as HTTP?
- Authentication patterns (API keys vs OAuth)?
- Rate limiting + error handling?
- WebSocket vs HTTP for real-time events?

**2. Cloud Deployment:**
- Fly.io vs Railway vs DigitalOcean comparison?
- Cost optimization (free tier limits)?
- Secrets management (Fly secrets vs Vault)?
- Docker volume persistence guarantees?

**3. Telegram Bot API:**
- Approval workflow UX patterns?
- Button callback reliability?
- Message formatting (Markdown vs HTML)?
- Webhook vs polling for button clicks?

**4. Multi-Model Orchestration:**
- Routing logic (task type â†’ optimal model)?
- Cost tracking (Langfuse per-model)?
- Failure handling (model unavailable)?
- Context sharing (one model's output â†’ another's input)?

**5. Security & Privacy:**
- API authentication (JWT vs API keys)?
- Secrets rotation (Telegram bot token)?
- Data sovereignty (self-hosted vs managed)?
- Audit logging (who approved what, when)?

---

## 10. ××¡×§× ×•×ª ×•××©×™××” ×œ-GPT

### ××¡×§× ×” ××¨×›×–×™×ª
**×”××¢×¨×›×ª ××•×›× ×” ×œ××¢×‘×¨ Headless.** ×œ× ××“×•×‘×¨ ×‘"×©×™× ×•×™ ××¨×›×™×˜×§×˜×•×¨×™ ×’×“×•×œ" ××œ× ×‘-**×”×•×¦××” ×œ×¤×•×¢×œ ×©×œ ×”××¨×›×™×˜×§×˜×•×¨×” ×”×§×™×™××ª** (Hexagonal + MAPE-K).

### ×”××©×™××” ×œ-GPT
×‘×¦×¢ Deep Research ×¢×œ ×”× ×•×©××™× ×”×‘××™×:

1. **MCP â†’ REST Best Practices** (4-6 sources, industry standard)
2. **Cloud VPS Comparison** (Fly.io, Railway, DigitalOcean)
3. **Telegram Bot API Patterns** (approval workflows)
4. **Multi-Model Orchestration** (routing + cost optimization)
5. **Security Considerations** (auth, secrets, audit)

**×¤×•×¨××˜ ×”×“×•×— ×”××‘×•×§×©:**
- Executive Summary (200 words)
- Detailed Analysis (5 sections, 1000 words each)
- Decision Matrix (pros/cons table for each option)
- Recommended Path (specific steps + rationale)
- Cost Analysis ($0-5/month target)
- Risk Assessment (low/medium/high for each component)

**×ª×•×¦×¨:** ×“×•×— PDF 20-30 ×¢××•×“×™×, ××‘×•×¡×¡ ×¢×œ ××§×•×¨×•×ª ××•×›×—×™× (××§×“××™×” + ×ª×¢×©×™×™×”)

---

**End of Document**  
**Version:** 1.0  
**Date:** 2025-12-05  
**Status:** Ready for GPT Deep Research  
**Next Action:** Send to GPT with research questions (Section 9)