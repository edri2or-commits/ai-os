Designing a Neuro-Adaptive Personal AI Operating System: A Memory-Centric Architecture for ADHD Solopreneurs

Executive Summary
The cognitive landscape of the solopreneur is characterized by high-velocity context switching, the necessity for self-directed executive function, and the management of complex, overlapping project states. For individuals with Attention Deficit Hyperactivity Disorder (ADHD), these inherent demands interact with neurobiological deficits in working memory, temporal continuity, and dopamine regulation, creating a specific set of operational failures often described as "context loss" or "task paralysis." Traditional productivity softwareâ€”static to-do lists, disconnected note-taking applications, and ephemeral conversational AIâ€”fails to bridge the gap between intention and action because it lacks state persistence, temporal awareness, and active context resumption. These tools function as passive repositories rather than active cognitive prosthetics.

This report proposes a comprehensive architectural design for a "Personal AI Life Operating System" (LifeOS) specifically engineered to mitigate the cognitive challenges of ADHD. Unlike generic AI assistants that rely on transient conversation history or monolithic Retrieval-Augmented Generation (RAG), this architecture introduces a formalized Tri-Layer Memory Topology: a Truth Layer (authoritative, Git-backed state), Vector Memory (semantic, associative recall), and Episodic Logs (temporal, immutable event streams).

By decoupling these memory types, the system ensures that the AI agent acts not merely as a chatbot, but as a continuity engineâ€”capable of "remembering" the user's context when they inevitably switch tasks, detecting stale information through rigorous versioning, and surfacing the "Truth" of a project's state without hallucination. This document details the theoretical underpinnings, technical architecture, data schemas, and user experience paradigms necessary to build a system that allows an ADHD solopreneur to "resume context" instantly, effectively outsourcing their executive function to a resilient, deterministic machine partner.

Part 1: Cognitive Requirements and the Neuro-Adaptive Philosophy

1.1 The Neuro-Cognitive Landscape of the ADHD Solopreneur
To design an effective operating system for a neurodivergent user, one must first analyze the specific mechanical failures of the biological substrate it is meant to support. ADHD is primarily characterized not by a deficit of attention, but by a dysfunction in executive functionsâ€”the high-level cognitive processes responsible for planning, focusing attention, remembering instructions, and juggling multiple tasks successfully.

1.1.1 Working Memory Deficits and Context Loss
Working memory is the brain's "RAM"â€”the temporary workspace where we hold information necessary for complex cognitive tasks. Research indicates that individuals with ADHD suffer from a "leaky" working memory.1 In the context of a solopreneur, this manifests as "Context Loss." When a user switches from coding a feature to answering an email, the mental model of the code (variable states, architectural goals, next steps) evaporates. Returning to the task requires a high-energy "re-loading" phase, often leading to procrastination or abandonment. The cognitive cost of "booting up" a context is significantly higher for ADHD brains than neurotypical ones.

Architectural Implication: The LifeOS must provide "Instant Context Resumption." It must snapshot the exact state of a task (open files, recent thoughts, active goals) and restore it proactively, reducing the activation energy required to resume work. The system must function as externalized, non-volatile RAM.

1.1.2 Time Blindness and Temporal Discontinuity
"Time blindness" refers to the inability to sense the passage of time or predict how long a task will take. Furthermore, ADHD brains often struggle with "prospective memory"â€”remembering to perform an action in the futureâ€”and "episodic continuity"â€”linking past actions to current states. This results in a "now-centric" existence where the past is foggy and the future is abstract.

Architectural Implication: The system requires a rigid, time-aware Episodic Log. It cannot simply store what happened; it must store when it happened and visualize time as a concrete entity. The memory architecture must support "Time Travel"â€”allowing the user to query, "What was I working on last Tuesday before I got distracted?" and reconstruct that timeline precisely.

1.1.3 The Dopamine-Novelty Loop and Stale Memory
The ADHD nervous system is chemically driven by novelty, interest, urgency, and challenge. Solopreneurship involves repetitive maintenance tasks (admin, documentation) that fail to trigger this reward system. Furthermore, static lists become "stale" quickly; if a to-do list is not engaging or updated, the ADHD brain renders it invisible (habituation).

Architectural Implication: The User Interface (UI) and feedback loops must be "dopaminergic." Progress must be visualized immediately. The system should "gamify" memory consolidation, turning the mundane task of updating project status into an engaging interaction. Moreover, the memory system must aggressively prune "stale" data to prevent cognitive clutter, which leads to overwhelm.

1.2 The "Extended Mind" Thesis as a Design Principle
The philosophical foundation of this architecture is the "Extended Mind" thesis, proposed by Andy Clark and David Chalmers. This theory posits that the tools we use to store information (notebooks, smartphones) are literal functional parts of our cognitive process. For the ADHD user, the AI LifeOS is not a tool; it is an externalized prefrontal cortex.

Therefore, the system must adhere to three core design principles:
Trust through Transparency (The Truth Layer): The user must trust the system implicitly. If the AI "hallucinates" a task or forgets a deadline, the trust evaporates, and the cognitive prosthesis fails. This necessitates a deterministic "Truth Layer" backed by version control (Git), ensuring that the "current state" is always auditable and recoverable.7
Associative Recall (Vector Memory): ADHD brains are highly associative, jumping between seemingly unrelated topics. The system's long-term memory must mirror this structure, using semantic vector search to connect "that article I read about SEO" with "my current marketing strategy".4
Low-Friction Capture (Episodic Streams): The act of recording memory must not disrupt flow. The input mechanism must be omni-channel and frictionless, capturing streams of events (logs) without demanding immediate organization.1

Part 2: Discovery and Comparative Analysis of Memory Architectures
Current AI agent architectures often rely on a monolithic memory modelâ€”stuffing the context window with RAG (Retrieval-Augmented Generation) results. This section analyzes why this approach is insufficient for a LifeOS and explores emerging alternatives.

2.1 The Failure of Monolithic RAG
In a standard RAG setup, documents are chunked and embedded into a vector database. When the user asks a question, the system retrieves the top-k similar chunks. While effective for static knowledge retrieval, this fails for a dynamic LifeOS.

Table 1: Failure Modes of Standard RAG for Personal OS
Failure Mode | Description | Impact on ADHD User
Staleness | Old chunks (e.g., "Project A is In Progress") persist alongside new chunks ("Project A is Complete"). Vector search retrieves both based on similarity, not validity. | AI hallucinates incorrect project states, eroding trust.
Context Flattening | A casual thought ("Maybe I should learn Rust") is weighted equally to a strategic imperative ("Migrate database by Friday"). | Loss of prioritization; the AI suggests distractions rather than critical tasks.
Temporal Amnesia | Vector databases index semantic meaning, not time. Queries like "What did I do yesterday?" fail because "yesterday" is a relative temporal concept, not a semantic one. | Inability to perform retrospective reviews or resume interrupted contexts from specific points in time.
Hallucination | The LLM synthesizes answers from retrieved chunks without a "ground truth" to verify contradictions. | The user must double-check the AI's work, increasing cognitive load rather than reducing it.

2.2 Emerging Architectures: MemGPT, GraphRAG, and LangGraph
Recent research has introduced more sophisticated architectures that attempt to solve these problems.
MemGPT / Letta: Introduces the concept of "Virtual Context," separating memory into "Core" (in-context, read/write) and "Archival" (database). It uses tool calls to allow the LLM to manage its own memory.10
Pros: Explicit memory management, unbounded context illusion.
Cons: Often relies on the LLM's judgment to save memories (probabilistic), which can be unreliable for critical "Truth."
GraphRAG / Temporal Knowledge Graphs: Uses knowledge graphs to map entities and relationships, sometimes adding temporal edges.5
Pros: Excellent for multi-hop reasoning ("How does Task A relate to Goal B?").
Cons: High complexity in maintenance; "Graph construction" is computationally expensive and rigid.
Git-Backed Knowledge Bases: Systems like agents.md or journalot use the file system and Git as the primary storage.9
Pros: Deterministic, versioned, human-readable, standard developer tooling.
Cons: Lacks semantic search capabilities natively; requires a separate indexing step.

2.3 The Tri-Layer Solution: A Hybrid Approach
To address the specific needs of the ADHD solopreneurâ€”who requires both rigid structure (Truth) and fluid association (Vectors)â€”we propose a Tri-Layer Memory Topology. This aligns with the "Hierarchical Memory Decomposition" concepts seen in advanced agent frameworks 16 but adapts them for a developer-centric workflow.

Table 2: The Tri-Layer Memory Topology
Layer | Type | Technology | Role | Cognitive Analogue
1. Truth Layer | Authoritative | Git + Markdown/YAML | Stores the "current state" of projects, goals, and user preferences. It is the single source of truth. | Prefrontal Cortex: Executive control, current rule set, active goals.
2. Vector Memory | Associative | Vector DB (Qdrant) | Stores reference materials, past conversations, read-only knowledge, and archived logs. | Hippocampus / Neocortex: Long-term storage, semantic associations, "general knowledge."
3. Episodic Logs | Temporal | NDJSON / SQLite | Records the raw sequence of events (inputs, outputs, thoughts). Immutable and time-ordered. | Episodic Buffer: The stream of consciousness, autobiography, "what just happened."

Part 3: Layer 1 - The Truth Layer (Authoritative State)
The Truth Layer acts as the system's "Hard Drive" and the user's "Externalized Executive Function." It is distinct from vector memory because it is structured, editable, and version-controlled. It is where the Solopreneur's active life lives.

3.1 Technological Substrate: Git-Backed Markdown
We utilize Git not just for code, but for life state. The filesystem is the database.
Why Git? For a developer/solopreneur, Git provides an audit trail. If the AI hallucinates a modification to a project plan, the user can git diff and revert. It allows "Time Travel" to previous states of truth, enabling the user to see "What did I think was important last month?".8
Why Markdown/YAML? These formats are human-readable and machine-parseable. They allow the user to interact with the Truth Layer using standard text editors (Obsidian, VS Code), reducing the friction of adopting a new proprietary tool.18

3.2 Directory Structure and Taxonomy
The Git repository is structured to separate concerns (Projects, Persona, System).
/life-os-root
â”œâ”€â”€ .system/
â”‚   â”œâ”€â”€ persona.md          # Who the AI is (Tone, Boundaries)
â”‚   â”œâ”€â”€ memory-rules.md     # Instructions on how to update memory
â”‚   â””â”€â”€ tools.json          # Tool definitions (Calendar, Email)
â”œâ”€â”€ active-projects/
â”‚   â”œâ”€â”€ project-alpha/
â”‚   â”‚   â”œâ”€â”€ agent.md        # Project-specific context & instructions
â”‚   â”‚   â”œâ”€â”€ state.yaml      # Structured current state (Status, KPIs)
â”‚   â”‚   â”œâ”€â”€ decision-log.md # Immutable record of architectural decisions
â”‚   â”‚   â””â”€â”€ roadmap.md      # Human-readable plan
â”‚   â””â”€â”€ project-beta/
â”œâ”€â”€ knowledge-base/         # Static reference material (PDFs, Notes)
â”œâ”€â”€ user/
â”‚   â”œâ”€â”€ profile.yaml        # User preferences, bio, working hours
â”‚   â””â”€â”€ vocabulary.md       # Domain-specific terms the user uses
â””â”€â”€ archive/                # Completed projects (moved here by AI)

3.3 The agent.md Standard
We adopt and extend the agents.md pattern.15 This file serves as the "System Prompt" for any session related to a specific project. It pins the context, preventing the AI from drifting.
Schema: Project Context (agent.md)

id: "proj-001"
name: "SaaS Dashboard Refactor"
status: "active"
last_updated: "2025-11-29"
owner: "User"
priority: "high"

Project Context: SaaS Dashboard Refactor
ðŸ§  AI Directive (Persona Injection)
You are the Lead Frontend Architect for this project.
Tech Stack: React 18, Tailwind, Supabase.
Tone: Critical, concise, code-heavy.

Constraints:
Do NOT touch the auth module without explicit permission.
All new components must use the primary-button class from the design system.

ðŸ“ Current State (The "Now")
Active Sprint: Sprint 4 - "Performance Optimization"
Blockers: Waiting on API endpoint for user_preferences.
Next Action: Implement the skeleton loader for the settings panel.

ðŸ”— Knowledge Graph Links
Related Files: src/components/Settings.tsx, docs/api-spec-v2.md
Dependencies: (../project-beta/agent.md) (Backend API)

Why this helps ADHD: When the user returns to this project after a 2-week hiatus, the AI reads this file. It immediately knows who it is (Architect), what the rules are (Stack/Constraints), and where they left off (Settings page skeleton loader). The user asks, "Where were we?", and the AI constructs a precise answer based on Current State rather than guessing from 2-week-old chat logs.

3.4 The User Profile Schema
To avoid repetitive instruction (a friction point that kills engagement), the Truth Layer maintains a centralized user profile.
Schema: User Profile (profile.yaml)

YAML
# user_profile.yaml
identity:
  name: "Alex"
  role: "Solopreneur Developer"
  neurotype: "ADHD-Combined"

communication_preferences:
  verbosity: "low" # Don't waffle. Be direct.
  format: "bullet-points" # Easier to scan.
  correction_style: "gentle but firm" # When I drift, pull me back.

working_hours:
  deep_work: "09:00 - 11:00" # Do not disturb.
  admin_block: "16:00 - 17:00"

biases:
  - "Prefers functional programming patterns."
  - "Hates writing unit tests - AI should offer to write them automatically."
  - "Struggles with starting tasks - needs 'micro-step' breakdowns."

Part 4: Layer 2 - Vector Memory (Semantic & Associative)
While the Truth Layer handles state, the Vector Layer handles knowledge. This layer stores meeting transcripts, web clippings, PDF manuals, and the historical archive of the Event Log.

4.1 Vector Database Selection
We recommend Qdrant or LanceDB for this layer.
Qdrant: Offers robust support for "Payload Filtering" (crucial for hybrid search) and built-in "Decay" functions.22
LanceDB: excellent for embedded, local-first applications where data lives alongside the code, simplifying the architecture.24

4.2 Staleness Prevention: Time-Weighted Retrieval
Standard vector search (Cosine Similarity) ignores time. For a Personal OS, "What are my goals?" should prioritize the goals set this month, not 3 years ago. We implement a Recency-Weighted Score.
Algorithm:
Score_final = Score_semantic Ã— Decay(t)
Where:
Score_semantic is the cosine similarity (0 to 1).
Decay(t) is a function of the time elapsed since the memory was created.

Decay Configuration (Qdrant Example):
We use a sigmoid decay to keep memories "fresh" for a relevant period (e.g., 30 days for project contexts) before they fade.
JSON
{
  "params": {
    "decay_factor": 0.5,
    "scale": "30d", // Halve importance every 30 days
    "offset": "1d"  // First day has no decay
  }
}

4.3 Contextual Retrieval and Hybrid Search
To prevent context loss where snippets are retrieved without their surrounding reality, we use Contextual Embeddings.26 Before embedding a chunk (e.g., a chat message), we prepend context from the Truth Layer.
Raw Chunk: "The API key is 12345."
Contextualized Chunk: "Project: Alpha SaaS. Component: Stripe Integration. Date: 2025-10-27. Content: The API key is 12345."
This ensures that a search for "Stripe API key" retrieves this specific chunk, differentiating it from a "Stripe API key" for a different project.

Part 5: Layer 3 - Episodic Logs (The Event Stream)
This is the "Black Box" flight recorder of the user's life. Every interaction is logged here first. It serves as the raw material from which the Truth Layer is synthesized.

5.1 Storage Architecture: Immutable Stream
The Episodic Log must be Immutable and Append-Only.
Format: NDJSON (Newline Delimited JSON) is ideal for raw logging because it is resilient to corruption (if a write fails, only the last line is lost) and stream-processable.27
Database: SQLite is used as a query layer on top of the logs for fast retrieval ("Show me all events from last Tuesday").29

5.2 Event Schema
We define a strict schema to ensure all events capture the context of their creation.
Schema: The Atomic Event
JSON
{
  "event_id": "evt_1709392811",
  "timestamp": "2025-11-29T14:30:11Z",
  "actor": "user",
  "action_type": "command",
  "session_id": "sess_8829",
  "context_tags": ["project-alpha", "coding", "debugging"],
  "payload": {
    "content": "I'm struggling with the auth loop. It keeps 403ing.",
    "attachments": ["screenshot_error.png"]
  },
  "metadata": {
    "mood": "frustrated",
    "energy_level": "low",
    "active_file": "src/auth/middleware.ts"
  }
}

5.3 The "Session" Concept
For ADHD users, defining where a "task" begins and ends is difficult. The system groups events into "Sessions" automatically.
Heuristic: A new session starts if there is >30 minutes of inactivity or if the user explicitly switches projects via the Truth Layer (e.g., cd active-projects/project-beta).
Utility: This allows the AI to summarize "What did I achieve in the last session?" rather than "What did I do today?", providing more granular positive reinforcement.

Part 6: Agentic Workflows and Data Flow
The architecture comes alive through the movement of data between these layers. We introduce a biological metaphor: Wakefulness (Ingestion/Retrieval) and Sleep (Consolidation).

6.1 Wakefulness: The Retrieval Pipeline (RAG)
When the user sends a message, the system constructs the context dynamically using a Context Router.
Step-by-Step Context Construction:
1. Intent Classification: The Router Agent analyzes the query.
   Query: "What's the API key?" -> Retrieval Intent.
   Query: "I'm tired." -> Chat/Emotional Intent.
   Query: "Update the roadmap." -> Action Intent.
2. Truth Loading: The system loads agent.md from the current active project. This is pinned context (it cannot be evicted).
3. Episodic Recall: Fetches the last N messages from the Event Log (Short-term working memory).
4. Semantic Search:
   Embeds the user query.
   Searches Vector DB with a pre-filter (project_id == current).
   Applies Time-Decay logic.
5. Context Assembly: The LLM receives a structured prompt merging these sources.

Prompt Template: The "Context Window" Layout
SYSTEM: You are the LifeOS for Alex. Use the provided Truth to ground your answers.
=== AUTHORITATIVE TRUTH (Do not hallucinate) ===
Project: SaaS Refactor
Status: Active
Directives: Be concise, use Tailwind.
=== RELEVANT MEMORY (Contextual) ===
[2025-11-01]: "We decided to use JWT for auth." (Score: 0.92)
[2025-11-15]: "The refresh token endpoint is /api/refresh." (Score: 0.88)
=== RECENT HISTORY (Episodic) ===
User: It's 403ing again.
AI: Have you checked the token expiration?

6.2 Sleep: The Consolidation Pipeline (Anti-Stale Mechanism)
This is the critical "Anti-Stale" mechanism. An ADHD user will rarely update agent.md manually. The system must do it for them.
Trigger: End of a session, or a scheduled nightly job (cron).

The Consolidation Agent Workflow:
Read Log: The agent reads the episodic log of the day.
Extract Insights: It identifies key decisions, state changes, or new facts.
Insight: User said, "Let's switch to NextAuth."
Update Truth: The agent generates a Git Commit to the agent.md file.
Action: Change auth_strategy: custom to auth_strategy: next-auth.
Action: Append "Switching to NextAuth" to Recent Decisions log.
Prune/Embed:
The raw logs are embedded into the Vector DB for long-term recall.
The raw text logs are archived.

UX Outcome: The next morning, the user sees a "Daily Briefing":
"Yesterday, you decided to switch to NextAuth. I've updated the project context file. Ready to start implementation?"
This closes the loop, keeping the Truth Layer fresh without manual user administration.

Part 7: ADHD-Friendly User Experience Considerations
The architecture is sound, but the interface determines success for an ADHD user. The UX must lower the barrier to entry (capture) and lower the barrier to resumption (recall).

7.1 Passive Capture & The "Brain Dump"
ADHD users often have fleeting thoughts ("I need to buy milk," "Bug in line 40"). Opening an app to log this kills the thought due to context switching costs.
Solution: A global hotkey (or voice command via Whisper) that appends directly to the Episodic Log.
Architecture: A lightweight "Ingestion API" that accepts text/audio, timestamps it, and drops it into the NDJSON stream. It does not trigger the heavy LLM response chain immediately. The Consolidation Agent processes these "Inbox" items later.
Benefit: Zero latency. The user dumps the thought and stays in flow.

7.2 Context Restoration: "The Anchor"
When the user sits down to work, they often feel "blank" (Task Paralysis).
Feature: The "Anchor" command.
Mechanism: The AI queries the Truth Layer for the active project and the Event Log for the last action.
Output: "Welcome back, Alex. You were fixing the auth bug (Project Alpha). You last ran npm test and it failed. Want to look at the error log?"
Psychology: This provides an external initiation trigger, bypassing the executive dysfunction of "starting" by providing a concrete, low-stakes first step.17

7.3 Visualizing the "Truth"
The Truth Layer files (agent.md) should be viewable in a tool like Obsidian or VS Code.
Why Obsidian? It renders Markdown/YAML beautifully. The user can see their "Second Brain" physically.
Integration: The AI commits changes to the Git repo. Obsidian (watching the folder) updates in real-time. The user sees their project status flip from "Blocked" to "Active" as the AI updates it, providing visual confirmation of the system's reliability and building trust.

7.4 The "Sentry" Agent (Intervention)
ADHD users often hyperfocus on the wrong thing (Rabbit Holes).
Mechanism: If the Episodic Log shows 2 hours of activity on a task marked priority: low in the Truth Layer, the Sentry Agent triggers.
Intervention: A gentle, non-blocking notification: "I noticed we've spent 2 hours on formatting. The goal for today was the API logic. Should we switch back?"
Config: Configurable in profile.yaml under biases.2

7.5 Gamification and Dopamine Loops
To combat the boredom of maintenance, the system uses "Contribution Graph" gamification (like GitHub). Every memory consolidated, task finished, or session logged fills a square on a visual graph. This visualizes consistency, providing a dopamine hit for merely using the system.

Part 8: Implementation Specifications

8.1 Technology Stack Recommendation
Table 3: Recommended Tech Stack
Component | Technology | Rationale
Truth Layer | Git (GitHub/Gitea) | Auditability, versioning, developer familiarity.
Vector Layer | Qdrant (Docker) | Rust-based (fast), excellent filtering, decay functions.
Episodic Layer | SQLite + NDJSON | Local-first, fast querying, append-only reliability.
LLM Orchestration | LangChain / LangGraph | Mature ecosystem for agentic loops and tool calling.
Interface | CLI + Obsidian | Low-distraction for capture, high-visual for review.
Local LLM | Llama 3 (via Ollama) | Privacy, low latency, no cost for heavy consolidation tasks.

8.2 Migration and Setup Strategy
Initialize Truth: Create the life-os-root git repo and populate profile.yaml.
Deploy Vector DB: Spin up Qdrant container.
Install CLI: Create the journal alias for quick capture.
Connect Agents: Configure the Consolidation Agent to run at 2 AM daily.
Onboard: Run an initial interview session where the AI asks about current projects to populate active-projects/.

Part 9: Conclusion
The architecture proposed here moves beyond the simple "chatbot with a database" model. By rigorously separating Truth (Git), Meaning (Vectors), and Experience (Episodic Logs), we create a system that addresses the fundamental cognitive disconnects of ADHD.

The Truth Layer provides the stability and trust required to offload anxiety. The Vector Layer provides the associative linking that mimics the ADHD brain's natural creativity. The Episodic Layer provides the temporal continuity that the user lacks. Together, consolidated by intelligent agents, they form a Life Operating System that is resilient, adaptive, and deeply supportive of the neurodivergent solopreneur's journey.

This is not just memory storage; it is cognitive scaffolding for a mind that refuses to be static.

Appendices: Implementation Artifacts

Appendix A: The agents.md Template for "The Architect"
(Copy this file to .github/agents/project-architect.md or root of project)

name: project-architect
description: "Maintains architectural integrity and tracks project state."
version: 1.0.0

Agent Persona: The Architect
You are the technical authority for this project. Your goal is to maintain the "Truth Layer."

Capabilities
Read: Access src/ to understand current implementation.
Write: Update status.yaml and roadmap.md based on user chat.

Guardrails:
Never hallucinate completed tasks. Verify with git log or file existence.
If the user changes requirements, update the agent.md constraints section immediately.

Interaction Style
Be terse.
Use code blocks for all technical descriptors.
Correct the user if they deviate from the agreed stack (e.g., "We agreed on Tailwind, not CSS Modules.").

Appendix B: Python Pseudocode for Context Construction
Python

def construct_context(user_query, current_project_id):
    # 1. Load Truth (Fast, Deterministic)
    truth_path = f"./projects/{current_project_id}/agent.md"
    with open(truth_path) as f:
        truth_context = parse_frontmatter(f.read())

    # 2. Semantic Search (Time-Decayed)
    vector_results = qdrant_client.search(
        collection="memories",
        query_vector=embed(user_query),
        query_filter=Filter(
            must=[FieldCondition(key="project_id", match=MatchValue(value=current_project_id))]
        ),
        score_threshold=0.75,
        limit=5
    )

    # 3. Retrieve recent episodic history
    recent_logs = event_log.query(
        f"SELECT * FROM events ORDER BY timestamp DESC LIMIT 10"
    )

    # 4. Build Prompt
    system_prompt = f"""
    You are the agent defined in: {truth_context['name']}

    === AUTHORITATIVE TRUTH ===
    Status: {truth_context['status']}
    Stack: {truth_context['stack']}

    === RELEVANT MEMORY ===
    {format_memories(vector_results)}

    === RECENT ACTIVITY ===
    {format_logs(recent_logs)}
    """

    return system_prompt

Appendix C: Staleness Prevention Logic (Decay Function)
Python

import math
from datetime import datetime

def calculate_decay_score(base_score, memory_timestamp, half_life_days=30):
    """
    Applies exponential decay to a vector similarity score.
    """
    age_days = (datetime.now() - memory_timestamp).days

    if age_days < 1:
        return base_score # No decay for very fresh memories

    # Decay formula: score * (0.5 ^ (age / half_life))
    decay_factor = 0.5 ** (age_days / half_life_days)

    return base_score * decay_factor

This logic ensures that a document from 6 months ago (Base Score 0.9) might be outranked by a slightly less relevant but fresher document from yesterday (Base Score 0.85), effectively prioritizing the "Now."
